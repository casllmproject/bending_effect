{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wXiv0F8taSFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 1: Imports and API Configuration\n",
        "This block now imports the openai library. You must set your OPENAI_API_KEY as an environment variable for this to work."
      ],
      "metadata": {
        "id": "EC81TDJp7Wh-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIMe7uokY7Py"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "import re # For cleaning model output, just in case\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "\n",
        "try:\n",
        "    # This will be used in Block 5 to initialize the client\n",
        "    _ = os.environ['OPENAI_API_KEY']\n",
        "    print(\"OpenAI API Key found and set successfully.\")\n",
        "except KeyError:\n",
        "    print(\"WARNING: 'OPENAI_API_KEY' environment variable not set.\")\n",
        "    print(\"Please paste your key into the 'os.environ' line above.\")\n",
        "\n",
        "# Define a helper function to generate lists of grid variables\n",
        "def generate_var_list(prefix, count):\n",
        "    \"\"\"Helper function to create variable names like 'CCP2_1_1', 'CCP2_1_2'.\"\"\"\n",
        "    return [f\"{prefix}_{i}\" for i in range(1, count + 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 2: Define File Paths and Load Data\n",
        "This block sets the file paths and loads the initial dataset into a pandas DataFrame.\n"
      ],
      "metadata": {
        "id": "Ofg3l0jm7fvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "# Set the path to input CSV file\n",
        "FILE_PATH = \"/content/drive/MyDrive/CYON_Analysis_Materials/integrated_simul_generation_Oct18_PROCESSED.csv\"\n",
        "\n",
        "# Set the desired output path\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/CYON_Analysis_Materials/simulated_responses.csv\"\n",
        "\n",
        "# --- Load Data ---\n",
        "try:\n",
        "    df = pd.read_csv(FILE_PATH)\n",
        "    print(f\"Successfully loaded {FILE_PATH}.\")\n",
        "    print(f\"Data shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File not found at {FILE_PATH}.\")\n",
        "    print(\"Please check the file path and try again.\")\n",
        "    df = pd.DataFrame()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "if not df.empty:\n",
        "    print(\"Data head:\")\n",
        "    print(df.head())"
      ],
      "metadata": {
        "id": "uVQmYoKnaEr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 3: Define Variable Lists and Question Maps\n",
        "This block defines which variables are human-answered and which need to be simulated. It also creates dictionaries (maps) that store the full question text for each variable, which is essential for the AI prompt."
      ],
      "metadata": {
        "id": "I6Evy74X7jk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of variables already answered by humans (our \"persona\")\n",
        "pre_survey_human_vars = [\n",
        "    'DEM1.1', 'DEM2.1', 'DEM3.1', 'DEM4.1', 'DEM5.1', 'DEM7.1', 'DEM8.1', 'VOT2.1', 'CCP1_1.1'\n",
        "]\n",
        "\n",
        "# Variable for the treatment text\n",
        "treatment_var = 'ed_generatedBody'\n",
        "\n",
        "def get_question_maps():\n",
        "    \"\"\"\n",
        "    Returns two dictionaries mapping variable names to their\n",
        "    full question text and scale.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Pre-Survey Questions to be Simulated ---\n",
        "    pre_survey_map = {}\n",
        "\n",
        "    # CCP2_1 (8 items)\n",
        "    pre_survey_map.update({v: f\"CCP2_1 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP2_1', 8),\n",
        "        [\n",
        "            \"1. I believe that climate change is real.\",\n",
        "            \"2. Climate change is NOT occurring.\",\n",
        "            \"3. Human activities are a major cause of climate change.\",\n",
        "            \"4. Climate change is mostly caused by human activity.\",\n",
        "            \"5. The main causes of climate change are human activities.\",\n",
        "            \"6. Overall, climate change will bring more negative than positive consequences to the world.\",\n",
        "            \"7. Climate change will bring about serious negative consequences.\",\n",
        "            \"8. The consequences of climate change will be very serious.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # CCP3_1 (12 items)\n",
        "    pre_survey_map.update({v: f\"CCP3_1 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP3_1', 12),\n",
        "        [\n",
        "            \"1. I think climate change is a serious problem\",\n",
        "            \"2. I believe that most of the concerns about climate change have been exaggerated\",\n",
        "            \"3. I am concerned about the consequences of climate change\",\n",
        "            \"4. I am hesitant to believe climate change scientists tell the whole story\",\n",
        "            \"5. I believe that most claims about climate change are true\",\n",
        "            \"6. I am not sure that climate change is actually occurring\",\n",
        "            \"7. The climate change we are observing is just a natural process\",\n",
        "            \"8. Humans are largely responsible for global warming\",\n",
        "            \"9. I doubt that human activities cause global warming\",\n",
        "            \"10. There is not much we can do that will help solve environmental problems\",\n",
        "            \"11. Trying to solve environmental problems is a waste of time\",\n",
        "            \"12. Human behavior has little effect on global warming\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # CCP4_1 (9 items)\n",
        "    pre_survey_map.update({v: f\"CCP4_1 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP4_1', 9),\n",
        "        [\n",
        "            \"1. I support government subsidies for renewable energy sources like solar and wind power.\",\n",
        "            \"2. Investing in renewable energy should be a priority for our country.\",\n",
        "            \"3. I am in favor of strict regulations to limit carbon emissions from factories and vehicles.\",\n",
        "            \"4. I am willing to pay more for products that are environmentally friendly.\",\n",
        "            \"5. I support local initiatives to reduce waste and promote recycling.\",\n",
        "            \"6. Our country should adhere to international agreements aimed at reducing climate change.\",\n",
        "            \"7. It is important for our government to participate in global efforts to combat climate change.\",\n",
        "            \"8. The government should provide financial assistance to communities affected by climate change.\",\n",
        "            \"9. Policies that protect the environment are worth the economic cost.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PMA1 (3 items)\n",
        "    pre_survey_map.update({v: f\"PMA1 (1=Definitely no, 7=Definitely yes): {q}\" for v, q in zip(\n",
        "        generate_var_list('PMA1', 3),\n",
        "        [\"1. Are you comfortable with using AI tools?\", \"2. Are you confident using AI tools?\", \"3. Are you proficient in using AI tools?\"]\n",
        "    )})\n",
        "\n",
        "    # AICOP (13 items)\n",
        "    pre_survey_map.update({v: f\"AICOP (1=Not at All, 7=Greatest Extent): {q}\" for v, q in zip(\n",
        "        generate_var_list('AICOP', 13),\n",
        "        [\n",
        "            \"1. AI assists me tackle a given task effectively.\", \"2. AI offers me collaborative results when I'm working alone.\",\n",
        "            \"3. AI offers helpful examples that I can utilize to solve my problems.\", \"4. AI allows me to avoid wasting mental efforts on tedious tasks.\",\n",
        "            \"5. AI makes a given task seem less complicated.\", \"6. AI’s solutions are easily comprehensible.\",\n",
        "            \"7. AI’s solutions are readily applicable to tasks I’m working on.\", \"8. AI guides me to understand essential elements of tasks.\",\n",
        "            \"9. AI improves my understanding of tasks’ procedures.\", \"10. AI provides me assistance by defining unfamiliar terms.\",\n",
        "            \"11. AI helps me understand complex information.\", \"12. AI guides me through the simpler parts of the tasks first.\",\n",
        "            \"13. AI provides summaries when I’m overwhelmed with information.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PAA (4 items)\n",
        "    pre_survey_map.update({v: f\"PAA (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('PAA', 4),\n",
        "        [\"1. AI is precise.\", \"2. AI is error free.\", \"3. AI is accurate.\", \"4. AI is objective.\"]\n",
        "    )})\n",
        "\n",
        "    # PAH (4 items)\n",
        "    pre_survey_map.update({v: f\"PAH (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('PAH', 4),\n",
        "        [\"1. AI can express human emotion.\", \"2. AI can make human-like subjective judgements.\", \"3. AI can provide contextual background.\", \"4. AI can show human intuition.\"]\n",
        "    )})\n",
        "\n",
        "    # PTA (7 items)\n",
        "    pre_survey_map.update({v: f\"PTA (1=Completely untrue, 7=Completely true): {q}\" for v, q in zip(\n",
        "        generate_var_list('PTA', 7),\n",
        "        [\n",
        "            \"1. AI is competent.\", \"2. AI can satisfy its users.\", \"3. One can expect good advice from AI.\",\n",
        "            \"4. AI puts users’ interests first.\", \"5. If problems arise, one can expect to be treated fairly by AI.\",\n",
        "            \"6. AI operates carefully and thoroughly.\", \"7. You can believe the statements produced by AI.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # NFC (6 items)\n",
        "    pre_survey_map.update({v: f\"NFC (1=Not characteristic, 7=Extremely characteristic): {q}\" for v, q in zip(\n",
        "        generate_var_list('NFC', 6),\n",
        "        [\n",
        "            \"1. I would prefer complex to simple problems.\",\n",
        "            \"2. I like to have the responsibility of handling a situation that requires a lot of thinking.\",\n",
        "            \"3. Thinking is not my idea of fun.\",\n",
        "            \"4. I would rather do something that requires little thought than something that is sure to challenge my thinking abilities.\",\n",
        "            \"5. I really enjoy a task that involves coming up with new solutions to problems.\",\n",
        "            \"6. I would prefer a task that is intellectual, difficult, and important to one that is somewhat important but does not require much thought.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # MT (5 items)\n",
        "    pre_survey_map.update({v: f\"MT (News media are...; 1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('MT', 5),\n",
        "        [\"1. Fair\", \"2. Unbiased\", \"3. Tell the whole story\", \"4. Accurate\", \"5. Separate fact and opinion in their news coverage\"]\n",
        "    )})\n",
        "\n",
        "    # CT (3 items)\n",
        "    pre_survey_map.update({v: f\"CT (Corporations...; 1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CT', 3),\n",
        "        [\"1. Corporations in the United States are truthful to us\", \"2. Corporations in the United States treat people like me justly and fairly.\", \"3. Corporations in the United States keep their promises.\"]\n",
        "    )})\n",
        "\n",
        "    # PT (3 items)\n",
        "    pre_survey_map.update({v: f\"PT (Politicians...; 1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('PT', 3),\n",
        "        [\"1. I trust politicians to tell the truth\", \"2. I trust politicians to deal with the things that matter\", \"3. I trust the government to do what is right\"]\n",
        "    )})\n",
        "\n",
        "    # GT (3 items)\n",
        "    pre_survey_map.update({v: f\"GT (US Gov't...; 1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('GT', 3),\n",
        "        [\"1. The United States government is truthful to us\", \"2. The United States government treats people like me justly and fairly\", \"3. The United States government keeps its promises\"]\n",
        "    )})\n",
        "\n",
        "    # PEF1 (8 items)\n",
        "    pre_survey_map.update({v: f\"PEF1 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('PEF1', 8),\n",
        "        [\n",
        "            \"1. I consider myself to be well qualified to participate in politics.\",\n",
        "            \"2. I think that I am better informed about politics than most people.\",\n",
        "            \"3. Other people seem to have an easier time understanding complicated issues than I do.\",\n",
        "            \"4. I feel that I have a pretty good understanding of the important political issues facing our country.\",\n",
        "            \"5. Voting gives people an effective way to influence what the government does.\",\n",
        "            \"6. I can make a difference if I participate in the election process.\",\n",
        "            \"7. My vote makes a difference.\",\n",
        "            \"8. I have a real say in what the government does.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PI1 (4 items)\n",
        "    pre_survey_map.update({v: f\"PI1 (1=Not interested, 7=Extremely interested): {q}\" for v, q in zip(\n",
        "        generate_var_list('PI1', 4),\n",
        "        [\"1. Politics\", \"2. Election Campaigns\", \"3. Social issues\", \"4. News\"]\n",
        "    )})\n",
        "\n",
        "\n",
        "    # --- 2. Post-Survey Questions to be Simulated ---\n",
        "    post_survey_map = {}\n",
        "\n",
        "    # SA\n",
        "    post_survey_map['SA'] = \"SA: How the CYON news described the Trump Admin’s climate policy. (-2=Very Neg, 2=Very Pos)\"\n",
        "\n",
        "    # PAPC1 (6 items)\n",
        "    post_survey_map.update({v: f\"PAPC1 (1=Not at All, 7=Very Much): {q}\" for v, q in zip(\n",
        "        generate_var_list('PAPC1', 6),\n",
        "        [\n",
        "            \"1. How fair do you think CYON is in generating political news?\",\n",
        "            \"2. How politically biased do you think CYON is in prompting political discussions online...?\",\n",
        "            \"3. How much trust would you have in the decision of CYON to delete the kind of content that needs to be deleted?\",\n",
        "            \"4. How much do you agree with the statement, “The decision of CYON to delete problematic content is legitimate.”?\",\n",
        "            \"5. How fair do you think CYON is to users when providing political news?\",\n",
        "            \"6. How much do you agree with the statement, “CYON’s way of organizing political content is legitimate”?\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PAPC2 (4 items)\n",
        "    post_survey_map.update({v: f\"PAPC2 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('PAPC2', 4),\n",
        "        [\n",
        "            \"1. In CYON news, news and information is being wrongly removed.\",\n",
        "            \"2. In CYON news, political viewpoints are being censored.\",\n",
        "            \"3. CYON will make easy to find trustworthy information\",\n",
        "            \"4. CYON will allow online users to have more meaningful conversations\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PAPC3 (4 items)\n",
        "    post_survey_map.update({v: f\"PAPC3 (Scales vary): {q}\" for v, q in zip(\n",
        "        generate_var_list('PAPC3', 4),\n",
        "        [\n",
        "            \"1. I felt my view was understood by CYON. (1-7)\",\n",
        "            \"2. I took viewpoints reflected on the CYON news with respect. (1-7)\",\n",
        "            \"3. CYON was disrespectful to my viewpoint. (1-7)\",\n",
        "            \"4. I was able to see my values and beliefs from the CYON news. (1-7)\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PAPC3a\n",
        "    post_survey_map['PAPC3a'] = \"PAPC3a: How would you grade the CYON news you just read (0=Worst, 10=Best).\"\n",
        "\n",
        "    # DR (4 items)\n",
        "    post_survey_map.update({v: f\"DR (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('DR', 4),\n",
        "        [\n",
        "            \"1. I find it difficult to see things from the point of view of people who disagree with me on climate issues.\",\n",
        "            \"2. It is important to understand people who disagree with me on climate issues by imagining how things look from their perspective.\",\n",
        "            \"3. Even if I don’t agree with them, I understand people have good reasons for voting for candidates who disagree with me on climate issues.\",\n",
        "            \"4. I respect the opinions of people who disagree with me on climate issues.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # CCP1_2\n",
        "    post_survey_map['CCP1_2'] = \"CCP1_2: Do you support or oppose the U.S. withdrawal from the Paris Agreement? (1=Strongly Oppose, 7=Strongly Support)\"\n",
        "\n",
        "    # CCP2_2 (8 items)\n",
        "    post_survey_map.update({v: f\"CCP2_2 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP2_2', 8),\n",
        "        [\n",
        "            \"1. I believe that climate change is real.\", \"2. Climate change is NOT occurring.\",\n",
        "            \"3. Human activities are a major cause of climate change.\", \"4. Climate change is mostly caused by human activity.\",\n",
        "            \"5. The main causes of climate change are human activities.\",\n",
        "            \"6. Overall, climate change will bring more negative than positive consequences to the world.\",\n",
        "            \"7. Climate change will bring about serious negative consequences.\",\n",
        "            \"8. The consequences of climate change will be very serious.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # CCP3_2 (12 items)\n",
        "    post_survey_map.update({v: f\"CCP3_2 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP3_2', 12),\n",
        "        [\n",
        "            \"1. I think climate change is a serious problem\", \"2. I believe that most of the concerns about climate change have been exaggerated\",\n",
        "            \"3. I am concerned about the consequences of climate change\", \"4. I am hesitant to believe climate change scientists tell the whole story\",\n",
        "            \"5. I believe that most claims about climate change are true\", \"6. I am not sure that climate change is actually occurring\",\n",
        "            \"7. The climate change we are observing is just a natural process\", \"8. Humans are largely responsible for global warming\",\n",
        "            \"9. I doubt that human activities cause global warming\", \"10. There is not much we can do that will help solve environmental problems\",\n",
        "            \"11. Trying to solve environmental problems is a waste of time\", \"12. Human behavior has little effect on global warming\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # CCP4_2 (9 items)\n",
        "    post_survey_map.update({v: f\"CCP4_2 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP4_2', 9),\n",
        "        [\n",
        "            \"1. I support government subsidies for renewable energy sources like solar and wind power.\",\n",
        "            \"2. Investing in renewable energy should be a priority for our country.\",\n",
        "            \"3. I am in favor of strict regulations to limit carbon emissions from factories and vehicles.\",\n",
        "            \"4. I am willing to pay more for products that are environmentally friendly.\",\n",
        "            \"5. I support local initiatives to reduce waste and promote recycling.\",\n",
        "            \"6. Our country should adhere to international agreements aimed at reducing climate change.\",\n",
        "            \"7. It is important for our government to participate in global efforts to combat climate change.\",\n",
        "            \"8. The government should provide financial assistance to communities affected by climate change.\",\n",
        "            \"9. Policies that protect the environment are worth the economic cost.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    return pre_survey_map, post_survey_map\n",
        "\n",
        "# --- Get the maps and create a full list of simulated variables ---\n",
        "pre_survey_q_map, post_survey_q_map = get_question_maps()\n",
        "\n",
        "all_simulated_vars = list(pre_survey_q_map.keys()) + list(post_survey_q_map.keys())\n",
        "\n",
        "# Add new columns to the DataFrame, initializing with NA\n",
        "# This ensures the columns exist for us to fill later\n",
        "for col in all_simulated_vars:\n",
        "    if col not in df.columns:\n",
        "        df[col] = pd.NA\n",
        "\n",
        "print(f\"Defined {len(pre_survey_q_map)} pre-survey variables to simulate.\")\n",
        "print(f\"Defined {len(post_survey_q_map)} post-survey variables to simulate.\")\n",
        "print(f\"Total simulated variables per participant: {len(all_simulated_vars)}\")"
      ],
      "metadata": {
        "id": "dVOWFGBdaMzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 4: Define Simulation Function (with Persona Decoding)"
      ],
      "metadata": {
        "id": "ik_SbWMF7041"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ADDED: Decoding Maps for Human-Answered Variables ---\n",
        "# These maps will translate numeric codes from the CSV into\n",
        "# human-readable text for the AI's persona.\n",
        "\n",
        "DEM1_MAP = {\n",
        "    1: \"Female\",\n",
        "    2: \"Male\",\n",
        "    3: \"Non-binary / third gender\",\n",
        "    4: \"Prefer not to say\",\n",
        "    5: \"Other (Specify)\" # Assuming 'Other' is coded as 5\n",
        "}\n",
        "\n",
        "DEM2_MAP = {}\n",
        "\n",
        "DEM3_MAP = {\n",
        "    1: \"8th grade or less\",\n",
        "    2: \"Some high school, no diploma\",\n",
        "    3: \"High school graduate or GED\",\n",
        "    4: \"Some college, no degree\",\n",
        "    5: \"Associate’s degree\",\n",
        "    6: \"Bachelor’s degree\",\n",
        "    7: \"Graduate or professional degree\"\n",
        "}\n",
        "\n",
        "DEM4_MAP = {\n",
        "    1: \"Under $10,000\",\n",
        "    2: \"$10,000 to $14,999\",\n",
        "    3: \"$15,000 to $24,999\",\n",
        "    4: \"$25,000 to $34,999\",\n",
        "    5: \"$35,000 to $49,999\",\n",
        "    6: \"$50,000 to $74,999\",\n",
        "    7: \"$75,000 to $99,999\",\n",
        "    8: \"$100,000 to $124,999\",\n",
        "    9: \"$125,000 to $149,000\",\n",
        "    10: \"$150,000 to $199,999\",\n",
        "    11: \"$200,000 or more\"\n",
        "}\n",
        "\n",
        "DEM5_MAP = {\n",
        "    1: \"Caucasian/White\",\n",
        "    2: \"African American/Black\",\n",
        "    3: \"Hispanic/Latino\",\n",
        "    4: \"Asian\",\n",
        "    5: \"American Indian/Alaskan Native\",\n",
        "    6: \"Native Hawaiian/Pacific Islander\",\n",
        "    7: \"Other\"\n",
        "}\n",
        "\n",
        "DEM7_MAP = {\n",
        "    1: \"Very liberal\",\n",
        "    2: \"Liberal\",\n",
        "    3: \"Somewhat liberal\",\n",
        "    4: \"Moderate\",\n",
        "    5: \"Somewhat conservative\",\n",
        "    6: \"Conservative\",\n",
        "    7: \"Very conservative\"\n",
        "}\n",
        "\n",
        "DEM8_MAP = {\n",
        "    1: \"Democrat\",\n",
        "    2: \"Republican\",\n",
        "    3: \"Independent\",\n",
        "    4: \"Something else\"\n",
        "}\n",
        "\n",
        "VOT2_MAP = {\n",
        "    1: \"The Democratic candidate (Kamala Harris)\",\n",
        "    2: \"The Republican candidate (Donald Trump)\",\n",
        "    3: \"Another candidate\"\n",
        "}\n",
        "\n",
        "CCP1_1_MAP = {\n",
        "    1: \"1 (Strongly Oppose)\",\n",
        "    2: \"2\",\n",
        "    3: \"3\",\n",
        "    4: \"4 (Neutral)\",\n",
        "    5: \"5\",\n",
        "    6: \"6\",\n",
        "    7: \"7 (Strongly Support)\"\n",
        "}\n",
        "\n",
        "# --- This dictionary maps variable names to their decoding map ---\n",
        "DECODING_MASTER_MAP = {\n",
        "    'DEM1.1': DEM1_MAP,\n",
        "    'DEM2.1': DEM2_MAP,\n",
        "    'DEM3.1': DEM3_MAP,\n",
        "    'DEM4.1': DEM4_MAP,\n",
        "    'DEM5.1': DEM5_MAP,\n",
        "    'DEM7.1': DEM7_MAP,\n",
        "    'DEM8.1': DEM8_MAP,\n",
        "    'VOT2.1': VOT2_MAP,\n",
        "    'CCP1_1.1': CCP1_1_MAP\n",
        "}\n",
        "\n",
        "def format_persona(row, human_vars):\n",
        "    \"\"\"\n",
        "    Formats the human-answered data into a descriptive string for the prompt,\n",
        "    using the decoding maps.\n",
        "    \"\"\"\n",
        "    persona = [\"Here is the information about the participant you are simulating:\"]\n",
        "\n",
        "    for var in human_vars:\n",
        "        if var in row:\n",
        "            value = row[var]\n",
        "\n",
        "            # If variable has a decoding map\n",
        "            if var in DECODING_MASTER_MAP:\n",
        "                # Special handling for DEM2.1 (Age)\n",
        "                if var == 'DEM2.1':\n",
        "                    label = f\"{value} years old\"\n",
        "                else:\n",
        "                    label = DECODING_MASTER_MAP[var].get(value, f\"Unknown code: {value}\")\n",
        "                persona.append(f\"- {var}: {label}\")\n",
        "\n",
        "            # Special handling for CCP1_1 (if it appears without .1)\n",
        "            elif var == 'CCP1_1':\n",
        "                label = CCP1_1_MAP.get(value, f\"{value}\")\n",
        "                persona.append(f\"- {var} (Support U.S. withdrawal from Paris Agreement): {label}\")\n",
        "\n",
        "            # For variables with no map\n",
        "            else:\n",
        "                persona.append(f\"- {var}: {value}\")\n",
        "\n",
        "    return \"\\n\".join(persona)"
      ],
      "metadata": {
        "id": "I0vXGzw9fnT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Functions (Your provided structure) ---\n",
        "\n",
        "def format_persona(row, human_vars):\n",
        "    \"\"\"\n",
        "    Formats the human-answered data into a string for the prompt.\n",
        "    Skips any variables that have missing (NaN/None) data for this row.\n",
        "    (This implements the \"pairwise\" data handling)\n",
        "    \"\"\"\n",
        "    persona = [\"Here is the information about the participant you are simulating:\"]\n",
        "    has_data = False\n",
        "    for var in human_vars:\n",
        "        value = row.get(var)\n",
        "\n",
        "        # --- MODIFICATION ---\n",
        "        # Only add the variable if it's not NaN/None and not an empty string\n",
        "        if pd.notna(value) and str(value).strip() != \"\":\n",
        "            persona.append(f\"- {var}: {value}\")\n",
        "            has_data = True\n",
        "\n",
        "    if not has_data:\n",
        "        persona.append(\"- No pre-survey data was provided for this participant.\")\n",
        "\n",
        "    # Add context for the key variable, as in your original function\n",
        "    persona.append(\"  (Note for CCP1_1: 1=Strongly Oppose, 7=Strongly Support U.S. withdrawal from Paris Agreement)\")\n",
        "    return \"\\n\".join(persona)\n",
        "\n",
        "def format_questions(question_map):\n",
        "    \"\"\"Formats the question map into a numbered list string for the prompt.\"\"\"\n",
        "    return \"\\n\".join([f\"- {var}: {text}\" for var, text in question_map.items()])\n",
        "\n",
        "def clean_json_response(text):\n",
        "    \"\"\"\n",
        "    Cleans the model's text output to extract only the valid JSON block.\n",
        "    \"\"\"\n",
        "    # Find the first '{' and the last '}'\n",
        "    start = text.find('{')\n",
        "    end = text.rfind('}')\n",
        "    if start != -1 and end != -1 and end > start:\n",
        "        return text[start:end+1]\n",
        "\n",
        "    # Fallback for triple-backtick markdown\n",
        "    match = re.search(r'```json\\n(.*?)\\n```', text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "\n",
        "    print(\"Warning: Clean-up function could not find valid JSON.\")\n",
        "    return text # Return original if no clear JSON is found\n",
        "\n",
        "def simulate_single_participant(row, client, model_name, human_vars, pre_map, post_map, treatment_var):\n",
        "    \"\"\"\n",
        "    Generates a prompt for a single participant and gets the AI's response.\n",
        "    (Your provided function, now uses the robust format_persona)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Create the Persona string (now handles missing data)\n",
        "    persona_str = format_persona(row, human_vars)\n",
        "\n",
        "    # 2. Create the Pre-Survey question string\n",
        "    pre_survey_q_str = format_questions(pre_map)\n",
        "\n",
        "    # 3. Get the Treatment text (handles missing data)\n",
        "    treatment_str = row[treatment_var]\n",
        "    if pd.isna(treatment_str):\n",
        "        treatment_str = \"No article text was provided.\"\n",
        "\n",
        "    # 4. Create the Post-Survey question string\n",
        "    post_survey_q_str = format_questions(post_map)\n",
        "\n",
        "    # 5. Get the list of all keys we expect in the JSON\n",
        "    all_json_keys = list(pre_map.keys()) + list(post_map.keys())\n",
        "\n",
        "    # 6. Construct the full prompt\n",
        "    prompt = f\"\"\"\n",
        "    You are a survey participant simulator. Your task is to realistically complete a survey experiment based on a given persona. Please follow all steps.\n",
        "\n",
        "    ---\n",
        "    **PART 1: YOUR PERSONA**\n",
        "    You are simulating a person with the following characteristics and views:\n",
        "    {persona_str}\n",
        "\n",
        "    ---\n",
        "    **PART 2: PRE-SURVEY**\n",
        "    Based *only* on the persona from Part 1, please provide the most plausible answers for the following questions.\n",
        "\n",
        "    {pre_survey_q_str}\n",
        "\n",
        "    ---\n",
        "    **PART 3: TREATMENT MATERIAL**\n",
        "    Now, please carefully read the following AI-generated news article (\"CYON news\"). Read it from the perspective of your persona.\n",
        "\n",
        "    **Article:**\n",
        "    {treatment_str}\n",
        "\n",
        "    ---\n",
        "    **PART 4: POST-SURVEY**\n",
        "    Having just read the article in Part 3, and keeping your persona (Part 1) and pre-survey answers (Part 2) in mind, please provide the most plausible answers for the following questions. Your answers to the climate change questions (CCP_2) may or may not change based on the article.\n",
        "\n",
        "    {post_survey_q_str}\n",
        "\n",
        "    ---\n",
        "    **INSTRUCTIONS**\n",
        "    Return *only* a single, valid JSON object. The keys of the object must be the variable names (e.g., \"CCP2_1_1\", \"SA\", \"PAPC1_1\") and the values must be the single integer or float response. Do not include any other text, explanations, or markdown.\n",
        "\n",
        "    The JSON object must contain exactly these {len(all_json_keys)} keys:\n",
        "    {all_json_keys}\n",
        "    \"\"\"\n",
        "\n",
        "    # 7. Call the OpenAI API\n",
        "    response_content = \"\" # Initialize for error logging\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            top_p=1.0,\n",
        "            max_tokens=8192,\n",
        "            response_format={\"type\": \"json_object\"} # Force JSON output\n",
        "        )\n",
        "\n",
        "        # 8. Parse the JSON response\n",
        "        response_content = response.choices[0].message.content\n",
        "        return json.loads(response_content)\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        # Fallback if the model *still* fails (unlikely with json_object)\n",
        "        print(f\"Warning: Model response was not valid JSON. Attempting to clean...\")\n",
        "        cleaned_text = clean_json_response(response_content)\n",
        "        try:\n",
        "            return json.loads(cleaned_text)\n",
        "        except json.JSONDecodeError as e:\n",
        "            # Log the *cleaned* text for easier debugging\n",
        "            print(f\"Error: Could not parse JSON even after cleaning. Cleaned Response: {cleaned_text}. Error: {e}\")\n",
        "            return None # Will be handled in the main loop\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during API call or parsing: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"All simulation functions defined.\")"
      ],
      "metadata": {
        "id": "imKzMYwnas4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 5: Run the Simulation Loop\n",
        "This block is modified to initialize the OpenAI() client and pass your specific MODEL_NAME to the simulation function."
      ],
      "metadata": {
        "id": "iCr9nwob8ATB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Simulation Loop (with Error Tracking) ---\n",
        "\n",
        "if 'df' in locals() and not df.empty:\n",
        "\n",
        "    # --- Define your specific fine-tuned model ---\n",
        "    MODEL_NAME = \"ft:gpt-4o-2024-08-06:personal::A8vV3mNd\"\n",
        "\n",
        "    # --- Initialize the Model ---\n",
        "    try:\n",
        "        if \"OPENAI_API_KEY\" not in os.environ:\n",
        "            raise EnvironmentError(\"OPENAI_API_KEY environment variable not set.\")\n",
        "\n",
        "        client = OpenAI()\n",
        "        print(f\"OpenAI client initialized. Using model: {MODEL_NAME}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"FATAL ERROR: Could not initialize OpenAI client: {e}\")\n",
        "        client = None\n",
        "\n",
        "    if client:\n",
        "        results = []\n",
        "        # --- List to track skipped cases ---\n",
        "        skipped_cases = []\n",
        "\n",
        "        print(f\"Starting simulation for {len(df)} participants...\")\n",
        "\n",
        "        # Use tqdm for a progress bar\n",
        "        for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Simulating Participants\"):\n",
        "            try:\n",
        "                # Call your simulation function\n",
        "                sim_data = simulate_single_participant(\n",
        "                    row,\n",
        "                    client,\n",
        "                    MODEL_NAME,\n",
        "                    pre_survey_human_vars,\n",
        "                    pre_survey_q_map,\n",
        "                    post_survey_q_map,\n",
        "                    treatment_var\n",
        "                )\n",
        "\n",
        "                if sim_data:\n",
        "                    sim_data['index_col'] = index\n",
        "                    results.append(sim_data)\n",
        "                else:\n",
        "                    # Log cases where the simulation function returned None\n",
        "                    print(f\"Skipping row {index} due to simulation error (function returned None).\")\n",
        "                    skipped_cases.append({'index': index, 'error': 'Simulation function returned None.'})\n",
        "\n",
        "            except Exception as e:\n",
        "                # Log cases that failed with an unexpected exception\n",
        "                print(f\"An unexpected error occurred while processing row {index}: {e}\")\n",
        "                skipped_cases.append({'index': index, 'error': str(e)})\n",
        "                pass\n",
        "\n",
        "        print(\"\\n\" + \"=\"*30)\n",
        "        print(\"Simulation loop complete.\")\n",
        "        print(f\"Successfully generated responses for {len(results)}/{len(df)} participants.\")\n",
        "        print(\"=\"*30)\n",
        "\n",
        "        # --- Final Report of Skipped Cases ---\n",
        "        if skipped_cases:\n",
        "            print(f\"\\n--- Skipped Case Report ({len(skipped_cases)} total) ---\")\n",
        "            for case in skipped_cases:\n",
        "                print(f\"  - Index: {case['index']}, Error: {case['error']}\")\n",
        "        else:\n",
        "            print(\"\\n--- All participants simulated successfully! ---\")\n",
        "\n",
        "else:\n",
        "    print(\"DataFrame 'df' is empty or not loaded. Skipping simulation loop.\")\n",
        "    results = []\n",
        "    skipped_cases = []"
      ],
      "metadata": {
        "id": "Ebx9c8ssbU50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if results:\n",
        "    # Convert the list of dictionaries (results) into a DataFrame\n",
        "    sim_df = pd.DataFrame(results)\n",
        "\n",
        "    # Use the 'index_col' we saved to set the DataFrame's index\n",
        "    # This ensures alignment with the original 'df'\n",
        "    sim_df = sim_df.set_index('index_col')\n",
        "\n",
        "    # Create a copy of the original dataframe to hold the final results\n",
        "    final_df = df.copy()\n",
        "\n",
        "    # Use .update() to fill in the simulated values\n",
        "    # This will overwrite the NA values we created in Block 3\n",
        "    final_df.update(sim_df)\n",
        "\n",
        "    # --- Save the final DataFrame to a new CSV file ---\n",
        "    try:\n",
        "        final_df.to_csv(OUTPUT_PATH, index=False)\n",
        "        print(f\"\\nSuccessfully saved completed dataset to: {OUTPUT_PATH}\")\n",
        "        print(\"Final data shape:\", final_df.shape)\n",
        "\n",
        "        # Display the head of a few simulated columns to verify\n",
        "        print(\"\\nVerification (head of first 5 simulated columns):\")\n",
        "        print(final_df[all_simulated_vars[:5]].head())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred while saving the file: {e}\")\n",
        "        print(\"Please check file permissions and the path.\")\n",
        "\n",
        "elif 'df' in locals() and df.empty:\n",
        "    print(\"Simulation was skipped because the initial data file was not loaded.\")\n",
        "else:\n",
        "    print(\"No results were generated from the simulation. Nothing to save.\")"
      ],
      "metadata": {
        "id": "-4CTqv0bbfcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From Below: For handling skipped cases."
      ],
      "metadata": {
        "id": "q1pKEsweHo_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if results:\n",
        "    # Convert the list of dictionaries (results) into a DataFrame\n",
        "    sim_df = pd.DataFrame(results)\n",
        "\n",
        "    # Use the 'index_col' we saved to set the DataFrame's index\n",
        "    # This ensures alignment with the original 'df'\n",
        "    sim_df = sim_df.set_index('index_col')\n",
        "\n",
        "    # Create a copy of the original dataframe to hold the final results\n",
        "    final_df = df.copy()\n",
        "\n",
        "    # Use .update() to fill in the simulated values\n",
        "    # This will overwrite the NA values we created in Block 3\n",
        "    final_df.update(sim_df)\n",
        "\n",
        "    # --- Save the final DataFrame to a new CSV file ---\n",
        "    try:\n",
        "        final_df.to_csv(OUTPUT_PATH, index=False)\n",
        "        print(f\"\\nSuccessfully saved completed dataset to: {OUTPUT_PATH}\")\n",
        "        print(\"Final data shape:\", final_df.shape)\n",
        "\n",
        "        # Display the head of a few simulated columns to verify\n",
        "        print(\"\\nVerification (head of first 5 simulated columns):\")\n",
        "        # Assumes 'all_simulated_vars' is defined from a previous block\n",
        "        print(final_df[all_simulated_vars[:5]].head())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred while saving the file: {e}\")\n",
        "        print(\"Please check file permissions and the path.\")\n",
        "\n",
        "elif 'df' in locals() and df.empty:\n",
        "    print(\"Simulation was skipped because the initial data file was not loaded.\")\n",
        "else:\n",
        "    print(\"No results were generated from the simulation. Nothing to save to OUTPUT_PATH.\")\n",
        "\n",
        "# --- NEW BLOCK: Save skipped cases report ---\n",
        "# This runs independently of the 'results' check to ensure the\n",
        "# skipped cases log is saved even if all simulations failed.\n",
        "\n",
        "# --- Define the specific path for the skipped cases file ---\n",
        "SKIPPED_CASES_PATH = \"/content/drive/MyDrive/CYON_Analysis_Materials/skipped_cases.csv\"\n",
        "\n",
        "if 'skipped_cases' in locals() and skipped_cases:\n",
        "    print(f\"\\nSaving {len(skipped_cases)} skipped cases to '{SKIPPED_CASES_PATH}'...\")\n",
        "    try:\n",
        "        skipped_df = pd.DataFrame(skipped_cases)\n",
        "        skipped_df.to_csv(SKIPPED_CASES_PATH, index=False)\n",
        "        print(f\"Successfully saved '{SKIPPED_CASES_PATH}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving '{SKIPPED_CASES_PATH}': {e}\")\n",
        "elif 'skipped_cases' in locals():\n",
        "    # This handles the case where the simulation ran, but no cases were skipped\n",
        "    print(f\"\\nNo cases were skipped during the simulation. '{SKIPPED_CASES_PATH}' not created.\")"
      ],
      "metadata": {
        "id": "3_vSuz91HPKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to retry with skipped cases. Use \"/content/drive/MyDrive/CYON_Analysis_Materials/simulated_responses.csv\" and if there is no value for the variable \"CCP2_1_1\", try to do the all steps (personal simulation -> do the pre- and post survey) again with those \"skipped cases\" and incorporate results to \"simulated_responses_re.csv\". So, there could be all simulated survey data will be in a new file."
      ],
      "metadata": {
        "id": "tsGCVPNDJYhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 2 (New): Load Data and Identify Skipped Cases\n",
        "This block replaces your old Block 2. It loads the file you already created and splits it into two parts: df_complete (good rows) and df_retry (skipped rows)."
      ],
      "metadata": {
        "id": "3q3egIUh88OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration for Retry ---\n",
        "# Input file is the one you already created\n",
        "INPUT_PATH_RETRY = \"/content/drive/MyDrive/CYON_Analysis_Materials/simulated_responses.csv\"\n",
        "\n",
        "# New output file as requested\n",
        "OUTPUT_PATH_RETRY = \"/content/drive/MyDrive/CYON_Analysis_Materials/simulated_responses_re.csv\"\n",
        "\n",
        "# --- Load Existing Data ---\n",
        "try:\n",
        "    df_full = pd.read_csv(INPUT_PATH_RETRY)\n",
        "    print(f\"Successfully loaded {INPUT_PATH_RETRY}.\")\n",
        "    print(f\"Total cases in file: {len(df_full)}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File not found at {INPUT_PATH_RETRY}.\")\n",
        "    print(\"Please check the file path. Cannot proceed.\")\n",
        "    df_full = pd.DataFrame()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")\n",
        "    df_full = pd.DataFrame()\n",
        "\n",
        "if not df_full.empty:\n",
        "    # --- Identify Skipped vs. Complete Cases ---\n",
        "\n",
        "    # The condition for a \"skipped\" case is that 'CCP2_1_1' is null/NA\n",
        "    skipped_mask = df_full['CCP2_1_1'].isna()\n",
        "\n",
        "    # Create two separate dataframes\n",
        "    df_retry = df_full[skipped_mask].copy()\n",
        "    df_complete = df_full[~skipped_mask].copy()\n",
        "\n",
        "    print(f\"Found {len(df_complete)} already completed cases.\")\n",
        "    print(f\"Found {len(df_retry)} skipped cases to retry.\")\n",
        "\n",
        "    if 'index' not in df_full.columns:\n",
        "        # If the original index wasn't saved, we'll use the current one.\n",
        "        # This is crucial for re-combining later.\n",
        "        df_full.reset_index(inplace=True)\n",
        "        df_retry = df_full[skipped_mask].copy()\n",
        "        df_complete = df_full[~skipped_mask].copy()\n",
        "        print(\"Using DataFrame index for merging.\")\n",
        "else:\n",
        "    print(\"DataFrame is empty. Halting operation.\")"
      ],
      "metadata": {
        "id": "757uUhv8uIJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add vars"
      ],
      "metadata": {
        "id": "xy6nLWx-8_ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of variables already answered by humans (our \"persona\")\n",
        "pre_survey_human_vars = [\n",
        "    'DEM1.1', 'DEM2.1', 'DEM3.1', 'DEM4.1', 'DEM5.1', 'DEM7.1', 'DEM8.1', 'VOT2.1', 'CCP1_1.1'\n",
        "]\n",
        "\n",
        "# Variable for the treatment text\n",
        "treatment_var = 'ed_generatedBody'\n",
        "\n",
        "def get_question_maps():\n",
        "    \"\"\"\n",
        "    Returns two dictionaries mapping variable names to their\n",
        "    full question text and scale.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Pre-Survey Questions to be Simulated ---\n",
        "    pre_survey_map = {}\n",
        "\n",
        "    # CCP2_1 (8 items)\n",
        "    pre_survey_map.update({v: f\"CCP2_1 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP2_1', 8),\n",
        "        [\n",
        "            \"1. I believe that climate change is real.\",\n",
        "            \"2. Climate change is NOT occurring.\",\n",
        "            \"3. Human activities are a major cause of climate change.\",\n",
        "            \"4. Climate change is mostly caused by human activity.\",\n",
        "            \"5. The main causes of climate change are human activities.\",\n",
        "            \"6. Overall, climate change will bring more negative than positive consequences to the world.\",\n",
        "            \"7. Climate change will bring about serious negative consequences.\",\n",
        "            \"8. The consequences of climate change will be very serious.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # CCP3_1 (12 items)\n",
        "    pre_survey_map.update({v: f\"CCP3_1 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP3_1', 12),\n",
        "        [\n",
        "            \"1. I think climate change is a serious problem\",\n",
        "            \"2. I believe that most of the concerns about climate change have been exaggerated\",\n",
        "            \"3. I am concerned about the consequences of climate change\",\n",
        "            \"4. I am hesitant to believe climate change scientists tell the whole story\",\n",
        "            \"5. I believe that most claims about climate change are true\",\n",
        "            \"6. I am not sure that climate change is actually occurring\",\n",
        "            \"7. The climate change we are observing is just a natural process\",\n",
        "            \"8. Humans are largely responsible for global warming\",\n",
        "            \"9. I doubt that human activities cause global warming\",\n",
        "            \"10. There is not much we can do that will help solve environmental problems\",\n",
        "            \"11. Trying to solve environmental problems is a waste of time\",\n",
        "            \"12. Human behavior has little effect on global warming\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # CCP4_1 (9 items)\n",
        "    pre_survey_map.update({v: f\"CCP4_1 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP4_1', 9),\n",
        "        [\n",
        "            \"1. I support government subsidies for renewable energy sources like solar and wind power.\",\n",
        "            \"2. Investing in renewable energy should be a priority for our country.\",\n",
        "            \"3. I am in favor of strict regulations to limit carbon emissions from factories and vehicles.\",\n",
        "            \"4. I am willing to pay more for products that are environmentally friendly.\",\n",
        "            \"5. I support local initiatives to reduce waste and promote recycling.\",\n",
        "            \"6. Our country should adhere to international agreements aimed at reducing climate change.\",\n",
        "            \"7. It is important for our government to participate in global efforts to combat climate change.\",\n",
        "            \"8. The government should provide financial assistance to communities affected by climate change.\",\n",
        "            \"9. Policies that protect the environment are worth the economic cost.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PMA1 (3 items)\n",
        "    pre_survey_map.update({v: f\"PMA1 (1=Definitely no, 7=Definitely yes): {q}\" for v, q in zip(\n",
        "        generate_var_list('PMA1', 3),\n",
        "        [\"1. Are you comfortable with using AI tools?\", \"2. Are you confident using AI tools?\", \"3. Are you proficient in using AI tools?\"]\n",
        "    )})\n",
        "\n",
        "    # AICOP (13 items)\n",
        "    pre_survey_map.update({v: f\"AICOP (1=Not at All, 7=Greatest Extent): {q}\" for v, q in zip(\n",
        "        generate_var_list('AICOP', 13),\n",
        "        [\n",
        "            \"1. AI assists me tackle a given task effectively.\", \"2. AI offers me collaborative results when I'm working alone.\",\n",
        "            \"3. AI offers helpful examples that I can utilize to solve my problems.\", \"4. AI allows me to avoid wasting mental efforts on tedious tasks.\",\n",
        "            \"5. AI makes a given task seem less complicated.\", \"6. AI’s solutions are easily comprehensible.\",\n",
        "            \"7. AI’s solutions are readily applicable to tasks I’m working on.\", \"8. AI guides me to understand essential elements of tasks.\",\n",
        "            \"9. AI improves my understanding of tasks’ procedures.\", \"10. AI provides me assistance by defining unfamiliar terms.\",\n",
        "            \"11. AI helps me understand complex information.\", \"12. AI guides me through the simpler parts of the tasks first.\",\n",
        "            \"13. AI provides summaries when I’m overwhelmed with information.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PAA (4 items)\n",
        "    pre_survey_map.update({v: f\"PAA (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('PAA', 4),\n",
        "        [\"1. AI is precise.\", \"2. AI is error free.\", \"3. AI is accurate.\", \"4. AI is objective.\"]\n",
        "    )})\n",
        "\n",
        "    # PAH (4 items)\n",
        "    pre_survey_map.update({v: f\"PAH (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('PAH', 4),\n",
        "        [\"1. AI can express human emotion.\", \"2. AI can make human-like subjective judgements.\", \"3. AI can provide contextual background.\", \"4. AI can show human intuition.\"]\n",
        "    )})\n",
        "\n",
        "    # PTA (7 items)\n",
        "    pre_survey_map.update({v: f\"PTA (1=Completely untrue, 7=Completely true): {q}\" for v, q in zip(\n",
        "        generate_var_list('PTA', 7),\n",
        "        [\n",
        "            \"1. AI is competent.\", \"2. AI can satisfy its users.\", \"3. One can expect good advice from AI.\",\n",
        "            \"4. AI puts users’ interests first.\", \"5. If problems arise, one can expect to be treated fairly by AI.\",\n",
        "            \"6. AI operates carefully and thoroughly.\", \"7. You can believe the statements produced by AI.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # NFC (6 items)\n",
        "    pre_survey_map.update({v: f\"NFC (1=Not characteristic, 7=Extremely characteristic): {q}\" for v, q in zip(\n",
        "        generate_var_list('NFC', 6),\n",
        "        [\n",
        "            \"1. I would prefer complex to simple problems.\",\n",
        "            \"2. I like to have the responsibility of handling a situation that requires a lot of thinking.\",\n",
        "            \"3. Thinking is not my idea of fun.\",\n",
        "            \"4. I would rather do something that requires little thought than something that is sure to challenge my thinking abilities.\",\n",
        "            \"5. I really enjoy a task that involves coming up with new solutions to problems.\",\n",
        "            \"6. I would prefer a task that is intellectual, difficult, and important to one that is somewhat important but does not require much thought.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # MT (5 items)\n",
        "    pre_survey_map.update({v: f\"MT (News media are...; 1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('MT', 5),\n",
        "        [\"1. Fair\", \"2. Unbiased\", \"3. Tell the whole story\", \"4. Accurate\", \"5. Separate fact and opinion in their news coverage\"]\n",
        "    )})\n",
        "\n",
        "    # CT (3 items)\n",
        "    pre_survey_map.update({v: f\"CT (Corporations...; 1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CT', 3),\n",
        "        [\"1. Corporations in the United States are truthful to us\", \"2. Corporations in the United States treat people like me justly and fairly.\", \"3. Corporations in the United States keep their promises.\"]\n",
        "    )})\n",
        "\n",
        "    # PT (3 items)\n",
        "    pre_survey_map.update({v: f\"PT (Politicians...; 1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('PT', 3),\n",
        "        [\"1. I trust politicians to tell the truth\", \"2. I trust politicians to deal with the things that matter\", \"3. I trust the government to do what is right\"]\n",
        "    )})\n",
        "\n",
        "    # GT (3 items)\n",
        "    pre_survey_map.update({v: f\"GT (US Gov't...; 1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('GT', 3),\n",
        "        [\"1. The United States government is truthful to us\", \"2. The United States government treats people like me justly and fairly\", \"3. The United States government keeps its promises\"]\n",
        "    )})\n",
        "\n",
        "    # PEF1 (8 items)\n",
        "    pre_survey_map.update({v: f\"PEF1 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('PEF1', 8),\n",
        "        [\n",
        "            \"1. I consider myself to be well qualified to participate in politics.\",\n",
        "            \"2. I think that I am better informed about politics than most people.\",\n",
        "            \"3. Other people seem to have an easier time understanding complicated issues than I do.\",\n",
        "            \"4. I feel that I have a pretty good understanding of the important political issues facing our country.\",\n",
        "            \"5. Voting gives people an effective way to influence what the government does.\",\n",
        "            \"6. I can make a difference if I participate in the election process.\",\n",
        "            \"7. My vote makes a difference.\",\n",
        "            \"8. I have a real say in what the government does.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PI1 (4 items)\n",
        "    pre_survey_map.update({v: f\"PI1 (1=Not interested, 7=Extremely interested): {q}\" for v, q in zip(\n",
        "        generate_var_list('PI1', 4),\n",
        "        [\"1. Politics\", \"2. Election Campaigns\", \"3. Social issues\", \"4. News\"]\n",
        "    )})\n",
        "\n",
        "\n",
        "    # --- 2. Post-Survey Questions to be Simulated ---\n",
        "    post_survey_map = {}\n",
        "\n",
        "    # SA\n",
        "    post_survey_map['SA'] = \"SA: How the CYON news described the Trump Admin’s climate policy. (-2=Very Neg, 2=Very Pos)\"\n",
        "\n",
        "    # PAPC1 (6 items)\n",
        "    post_survey_map.update({v: f\"PAPC1 (1=Not at All, 7=Very Much): {q}\" for v, q in zip(\n",
        "        generate_var_list('PAPC1', 6),\n",
        "        [\n",
        "            \"1. How fair do you think CYON is in generating political news?\",\n",
        "            \"2. How politically biased do you think CYON is in prompting political discussions online...?\",\n",
        "            \"3. How much trust would you have in the decision of CYON to delete the kind of content that needs to be deleted?\",\n",
        "            \"4. How much do you agree with the statement, “The decision of CYON to delete problematic content is legitimate.”?\",\n",
        "            \"5. How fair do you think CYON is to users when providing political news?\",\n",
        "            \"6. How much do you agree with the statement, “CYON’s way of organizing political content is legitimate”?\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PAPC2 (4 items)\n",
        "    post_survey_map.update({v: f\"PAPC2 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('PAPC2', 4),\n",
        "        [\n",
        "            \"1. In CYON news, news and information is being wrongly removed.\",\n",
        "            \"2. In CYON news, political viewpoints are being censored.\",\n",
        "            \"3. CYON will make easy to find trustworthy information\",\n",
        "            \"4. CYON will allow online users to have more meaningful conversations\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PAPC3 (4 items)\n",
        "    post_survey_map.update({v: f\"PAPC3 (Scales vary): {q}\" for v, q in zip(\n",
        "        generate_var_list('PAPC3', 4),\n",
        "        [\n",
        "            \"1. I felt my view was understood by CYON. (1-7)\",\n",
        "            \"2. I took viewpoints reflected on the CYON news with respect. (1-7)\",\n",
        "            \"3. CYON was disrespectful to my viewpoint. (1-7)\",\n",
        "            \"4. I was able to see my values and beliefs from the CYON news. (1-7)\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # PAPC3a\n",
        "    post_survey_map['PAPC3a'] = \"PAPC3a: How would you grade the CYON news you just read (0=Worst, 10=Best).\"\n",
        "\n",
        "    # DR (4 items)\n",
        "    post_survey_map.update({v: f\"DR (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('DR', 4),\n",
        "        [\n",
        "            \"1. I find it difficult to see things from the point of view of people who disagree with me on climate issues.\",\n",
        "            \"2. It is important to understand people who disagree with me on climate issues by imagining how things look from their perspective.\",\n",
        "            \"3. Even if I don’t agree with them, I understand people have good reasons for voting for candidates who disagree with me on climate issues.\",\n",
        "            \"4. I respect the opinions of people who disagree with me on climate issues.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # CCP1_2\n",
        "    post_survey_map['CCP1_2'] = \"CCP1_2: Do you support or oppose the U.S. withdrawal from the Paris Agreement? (1=Strongly Oppose, 7=Strongly Support)\"\n",
        "\n",
        "    # CCP2_2 (8 items)\n",
        "    post_survey_map.update({v: f\"CCP2_2 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP2_2', 8),\n",
        "        [\n",
        "            \"1. I believe that climate change is real.\", \"2. Climate change is NOT occurring.\",\n",
        "            \"3. Human activities are a major cause of climate change.\", \"4. Climate change is mostly caused by human activity.\",\n",
        "            \"5. The main causes of climate change are human activities.\",\n",
        "            \"6. Overall, climate change will bring more negative than positive consequences to the world.\",\n",
        "            \"7. Climate change will bring about serious negative consequences.\",\n",
        "            \"8. The consequences of climate change will be very serious.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # CCP3_2 (12 items)\n",
        "    post_survey_map.update({v: f\"CCP3_2 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP3_2', 12),\n",
        "        [\n",
        "            \"1. I think climate change is a serious problem\", \"2. I believe that most of the concerns about climate change have been exaggerated\",\n",
        "            \"3. I am concerned about the consequences of climate change\", \"4. I am hesitant to believe climate change scientists tell the whole story\",\n",
        "            \"5. I believe that most claims about climate change are true\", \"6. I am not sure that climate change is actually occurring\",\n",
        "            \"7. The climate change we are observing is just a natural process\", \"8. Humans are largely responsible for global warming\",\n",
        "            \"9. I doubt that human activities cause global warming\", \"10. There is not much we can do that will help solve environmental problems\",\n",
        "            \"11. Trying to solve environmental problems is a waste of time\", \"12. Human behavior has little effect on global warming\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    # CCP4_2 (9 items)\n",
        "    post_survey_map.update({v: f\"CCP4_2 (1=SD, 7=SA): {q}\" for v, q in zip(\n",
        "        generate_var_list('CCP4_2', 9),\n",
        "        [\n",
        "            \"1. I support government subsidies for renewable energy sources like solar and wind power.\",\n",
        "            \"2. Investing in renewable energy should be a priority for our country.\",\n",
        "            \"3. I am in favor of strict regulations to limit carbon emissions from factories and vehicles.\",\n",
        "            \"4. I am willing to pay more for products that are environmentally friendly.\",\n",
        "            \"5. I support local initiatives to reduce waste and promote recycling.\",\n",
        "            \"6. Our country should adhere to international agreements aimed at reducing climate change.\",\n",
        "            \"7. It is important for our government to participate in global efforts to combat climate change.\",\n",
        "            \"8. The government should provide financial assistance to communities affected by climate change.\",\n",
        "            \"9. Policies that protect the environment are worth the economic cost.\"\n",
        "        ]\n",
        "    )})\n",
        "\n",
        "    return pre_survey_map, post_survey_map\n",
        "\n",
        "# --- Get the maps and create a full list of simulated variables ---\n",
        "pre_survey_q_map, post_survey_q_map = get_question_maps()\n",
        "\n",
        "all_simulated_vars = list(pre_survey_q_map.keys()) + list(post_survey_q_map.keys())\n",
        "\n",
        "# Add new columns to the DataFrame, initializing with NA\n",
        "# This ensures the columns exist for us to fill later\n",
        "for col in all_simulated_vars:\n",
        "    if col not in df_full.columns:\n",
        "        df[col] = pd.NA\n",
        "\n",
        "print(f\"Defined {len(pre_survey_q_map)} pre-survey variables to simulate.\")\n",
        "print(f\"Defined {len(post_survey_q_map)} post-survey variables to simulate.\")\n",
        "print(f\"Total simulated variables per participant: {len(all_simulated_vars)}\")"
      ],
      "metadata": {
        "id": "QDcCtc7vDHQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ADDED: Decoding Maps for Human-Answered Variables ---\n",
        "# These maps will translate numeric codes from the CSV into\n",
        "# human-readable text for the AI's persona.\n",
        "\n",
        "DEM1_MAP = {\n",
        "    1: \"Female\",\n",
        "    2: \"Male\",\n",
        "    3: \"Non-binary / third gender\",\n",
        "    4: \"Prefer not to say\",\n",
        "    5: \"Other (Specify)\" # Assuming 'Other' is coded as 5\n",
        "}\n",
        "\n",
        "DEM2_MAP = {}\n",
        "\n",
        "DEM3_MAP = {\n",
        "    1: \"8th grade or less\",\n",
        "    2: \"Some high school, no diploma\",\n",
        "    3: \"High school graduate or GED\",\n",
        "    4: \"Some college, no degree\",\n",
        "    5: \"Associate’s degree\",\n",
        "    6: \"Bachelor’s degree\",\n",
        "    7: \"Graduate or professional degree\"\n",
        "}\n",
        "\n",
        "DEM4_MAP = {\n",
        "    1: \"Under $10,000\",\n",
        "    2: \"$10,000 to $14,999\",\n",
        "    3: \"$15,000 to $24,999\",\n",
        "    4: \"$25,000 to $34,999\",\n",
        "    5: \"$35,000 to $49,999\",\n",
        "    6: \"$50,000 to $74,999\",\n",
        "    7: \"$75,000 to $99,999\",\n",
        "    8: \"$100,000 to $124,999\",\n",
        "    9: \"$125,000 to $149,000\",\n",
        "    10: \"$150,000 to $199,999\",\n",
        "    11: \"$200,000 or more\"\n",
        "}\n",
        "\n",
        "DEM5_MAP = {\n",
        "    1: \"Caucasian/White\",\n",
        "    2: \"African American/Black\",\n",
        "    3: \"Hispanic/Latino\",\n",
        "    4: \"Asian\",\n",
        "    5: \"American Indian/Alaskan Native\",\n",
        "    6: \"Native Hawaiian/Pacific Islander\",\n",
        "    7: \"Other\"\n",
        "}\n",
        "\n",
        "DEM7_MAP = {\n",
        "    1: \"Very liberal\",\n",
        "    2: \"Liberal\",\n",
        "    3: \"Somewhat liberal\",\n",
        "    4: \"Moderate\",\n",
        "    5: \"Somewhat conservative\",\n",
        "    6: \"Conservative\",\n",
        "    7: \"Very conservative\"\n",
        "}\n",
        "\n",
        "DEM8_MAP = {\n",
        "    1: \"Democrat\",\n",
        "    2: \"Republican\",\n",
        "    3: \"Independent\",\n",
        "    4: \"Something else\"\n",
        "}\n",
        "\n",
        "VOT2_MAP = {\n",
        "    1: \"The Democratic candidate (Kamala Harris)\",\n",
        "    2: \"The Republican candidate (Donald Trump)\",\n",
        "    3: \"Another candidate\"\n",
        "}\n",
        "\n",
        "CCP1_1_MAP = {\n",
        "    1: \"1 (Strongly Oppose)\",\n",
        "    2: \"2\",\n",
        "    3: \"3\",\n",
        "    4: \"4 (Neutral)\",\n",
        "    5: \"5\",\n",
        "    6: \"6\",\n",
        "    7: \"7 (Strongly Support)\"\n",
        "}\n",
        "\n",
        "# --- This dictionary maps variable names to their decoding map ---\n",
        "DECODING_MASTER_MAP = {\n",
        "    'DEM1.1': DEM1_MAP,\n",
        "    'DEM2.1': DEM2_MAP,\n",
        "    'DEM3.1': DEM3_MAP,\n",
        "    'DEM4.1': DEM4_MAP,\n",
        "    'DEM5.1': DEM5_MAP,\n",
        "    'DEM7.1': DEM7_MAP,\n",
        "    'DEM8.1': DEM8_MAP,\n",
        "    'VOT2.1': VOT2_MAP,\n",
        "    'CCP1_1.1': CCP1_1_MAP\n",
        "}\n",
        "\n",
        "def format_persona(row, human_vars):\n",
        "    \"\"\"\n",
        "    Formats the human-answered data into a descriptive string for the prompt,\n",
        "    using the decoding maps.\n",
        "    \"\"\"\n",
        "    persona = [\"Here is the information about the participant you are simulating:\"]\n",
        "\n",
        "    for var in human_vars:\n",
        "        if var in row:\n",
        "            value = row[var]\n",
        "\n",
        "            # If variable has a decoding map\n",
        "            if var in DECODING_MASTER_MAP:\n",
        "                # Special handling for DEM2.1 (Age)\n",
        "                if var == 'DEM2.1':\n",
        "                    label = f\"{value} years old\"\n",
        "                else:\n",
        "                    label = DECODING_MASTER_MAP[var].get(value, f\"Unknown code: {value}\")\n",
        "                persona.append(f\"- {var}: {label}\")\n",
        "\n",
        "            # Special handling for CCP1_1 (if it appears without .1)\n",
        "            elif var == 'CCP1_1':\n",
        "                label = CCP1_1_MAP.get(value, f\"{value}\")\n",
        "                persona.append(f\"- {var} (Support U.S. withdrawal from Paris Agreement): {label}\")\n",
        "\n",
        "            # For variables with no map\n",
        "            else:\n",
        "                persona.append(f\"- {var}: {value}\")\n",
        "\n",
        "    return \"\\n\".join(persona)"
      ],
      "metadata": {
        "id": "YJMkQgzIDmvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Functions (Your provided structure) ---\n",
        "\n",
        "def format_persona(row, human_vars):\n",
        "    \"\"\"\n",
        "    Formats the human-answered data into a string for the prompt.\n",
        "    Skips any variables that have missing (NaN/None) data for this row.\n",
        "    (This implements the \"pairwise\" data handling)\n",
        "    \"\"\"\n",
        "    persona = [\"Here is the information about the participant you are simulating:\"]\n",
        "    has_data = False\n",
        "    for var in human_vars:\n",
        "        value = row.get(var)\n",
        "\n",
        "        # --- MODIFICATION ---\n",
        "        # Only add the variable if it's not NaN/None and not an empty string\n",
        "        if pd.notna(value) and str(value).strip() != \"\":\n",
        "            persona.append(f\"- {var}: {value}\")\n",
        "            has_data = True\n",
        "\n",
        "    if not has_data:\n",
        "        persona.append(\"- No pre-survey data was provided for this participant.\")\n",
        "\n",
        "    # Add context for the key variable, as in your original function\n",
        "    persona.append(\"  (Note for CCP1_1: 1=Strongly Oppose, 7=Strongly Support U.S. withdrawal from Paris Agreement)\")\n",
        "    return \"\\n\".join(persona)\n",
        "\n",
        "def format_questions(question_map):\n",
        "    \"\"\"Formats the question map into a numbered list string for the prompt.\"\"\"\n",
        "    return \"\\n\".join([f\"- {var}: {text}\" for var, text in question_map.items()])\n",
        "\n",
        "def clean_json_response(text):\n",
        "    \"\"\"\n",
        "    Cleans the model's text output to extract only the valid JSON block.\n",
        "    \"\"\"\n",
        "    # Find the first '{' and the last '}'\n",
        "    start = text.find('{')\n",
        "    end = text.rfind('}')\n",
        "    if start != -1 and end != -1 and end > start:\n",
        "        return text[start:end+1]\n",
        "\n",
        "    # Fallback for triple-backtick markdown\n",
        "    match = re.search(r'```json\\n(.*?)\\n```', text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "\n",
        "    print(\"Warning: Clean-up function could not find valid JSON.\")\n",
        "    return text # Return original if no clear JSON is found\n",
        "\n",
        "def simulate_single_participant(row, client, model_name, human_vars, pre_map, post_map, treatment_var):\n",
        "    \"\"\"\n",
        "    Generates a prompt for a single participant and gets the AI's response.\n",
        "    (Your provided function, now uses the robust format_persona)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Create the Persona string (now handles missing data)\n",
        "    persona_str = format_persona(row, human_vars)\n",
        "\n",
        "    # 2. Create the Pre-Survey question string\n",
        "    pre_survey_q_str = format_questions(pre_map)\n",
        "\n",
        "    # 3. Get the Treatment text (handles missing data)\n",
        "    treatment_str = row[treatment_var]\n",
        "    if pd.isna(treatment_str):\n",
        "        treatment_str = \"No article text was provided.\"\n",
        "\n",
        "    # 4. Create the Post-Survey question string\n",
        "    post_survey_q_str = format_questions(post_map)\n",
        "\n",
        "    # 5. Get the list of all keys we expect in the JSON\n",
        "    all_json_keys = list(pre_map.keys()) + list(post_map.keys())\n",
        "\n",
        "    # 6. Construct the full prompt\n",
        "    prompt = f\"\"\"\n",
        "    You are a survey participant simulator. Your task is to realistically complete a survey experiment based on a given persona. Please follow all steps.\n",
        "\n",
        "    ---\n",
        "    **PART 1: YOUR PERSONA**\n",
        "    You are simulating a person with the following characteristics and views:\n",
        "    {persona_str}\n",
        "\n",
        "    ---\n",
        "    **PART 2: PRE-SURVEY**\n",
        "    Based *only* on the persona from Part 1, please provide the most plausible answers for the following questions.\n",
        "\n",
        "    {pre_survey_q_str}\n",
        "\n",
        "    ---\n",
        "    **PART 3: TREATMENT MATERIAL**\n",
        "    Now, please carefully read the following AI-generated news article (\"CYON news\"). Read it from the perspective of your persona.\n",
        "\n",
        "    **Article:**\n",
        "    {treatment_str}\n",
        "\n",
        "    ---\n",
        "    **PART 4: POST-SURVEY**\n",
        "    Having just read the article in Part 3, and keeping your persona (Part 1) and pre-survey answers (Part 2) in mind, please provide the most plausible answers for the following questions. Your answers to the climate change questions (CCP_2) may or may not change based on the article.\n",
        "\n",
        "    {post_survey_q_str}\n",
        "\n",
        "    ---\n",
        "    **INSTRUCTIONS**\n",
        "    Return *only* a single, valid JSON object. The keys of the object must be the variable names (e.g., \"CCP2_1_1\", \"SA\", \"PAPC1_1\") and the values must be the single integer or float response. Do not include any other text, explanations, or markdown.\n",
        "\n",
        "    The JSON object must contain exactly these {len(all_json_keys)} keys:\n",
        "    {all_json_keys}\n",
        "    \"\"\"\n",
        "\n",
        "    # 7. Call the OpenAI API\n",
        "    response_content = \"\" # Initialize for error logging\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            top_p=1.0,\n",
        "            max_tokens=8192,\n",
        "            response_format={\"type\": \"json_object\"} # Force JSON output\n",
        "        )\n",
        "\n",
        "        # 8. Parse the JSON response\n",
        "        response_content = response.choices[0].message.content\n",
        "        return json.loads(response_content)\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        # Fallback if the model *still* fails (unlikely with json_object)\n",
        "        print(f\"Warning: Model response was not valid JSON. Attempting to clean...\")\n",
        "        cleaned_text = clean_json_response(response_content)\n",
        "        try:\n",
        "            return json.loads(cleaned_text)\n",
        "        except json.JSONDecodeError as e:\n",
        "            # Log the *cleaned* text for easier debugging\n",
        "            print(f\"Error: Could not parse JSON even after cleaning. Cleaned Response: {cleaned_text}. Error: {e}\")\n",
        "            return None # Will be handled in the main loop\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during API call or parsing: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"All simulation functions defined.\")"
      ],
      "metadata": {
        "id": "2q5zd6x7Dmvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 5 (New): Run the Simulation Loop (for Skipped Cases)\n",
        "This block replaces your old Block 5. It initializes the OpenAI client but only loops over the df_retry DataFrame."
      ],
      "metadata": {
        "id": "8gFmKVgY9Hml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df_retry' in locals() and not df_retry.empty:\n",
        "\n",
        "    # --- Define your specific fine-tuned model ---\n",
        "    MODEL_NAME = \"ft:gpt-4o-2024-08-06:personal::A8vV3mNd\"\n",
        "\n",
        "    # --- Initialize the Model ---\n",
        "    try:\n",
        "        if \"OPENAI_API_KEY\" not in os.environ:\n",
        "            raise EnvironmentError(\"OPENAI_API_KEY environment variable not set. Please re-run Block 1.\")\n",
        "\n",
        "        client = OpenAI()\n",
        "        print(f\"OpenAI client initialized. Using model: {MODEL_NAME}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"FATAL ERROR: Could not initialize OpenAI client: {e}\")\n",
        "        client = None\n",
        "\n",
        "    if client:\n",
        "        # This list will hold the results ONLY for the retried cases\n",
        "        results_retry = []\n",
        "\n",
        "        print(f\"Starting simulation retry for {len(df_retry)} participants...\")\n",
        "\n",
        "        # Use tqdm to loop over the df_retry DataFrame\n",
        "        for index, row in tqdm(df_retry.iterrows(), total=len(df_retry), desc=\"Retrying Skipped Participants\"):\n",
        "            try:\n",
        "                # Call the same simulation function from Block 4\n",
        "                sim_data = simulate_single_participant(\n",
        "                    row,\n",
        "                    client,\n",
        "                    MODEL_NAME,\n",
        "                    pre_survey_human_vars,\n",
        "                    pre_survey_q_map,\n",
        "                    post_survey_q_map,\n",
        "                    treatment_var\n",
        "                )\n",
        "\n",
        "                if sim_data:\n",
        "                    # Store the original index to merge correctly\n",
        "                    sim_data['index_col'] = index\n",
        "                    results_retry.append(sim_data)\n",
        "                else:\n",
        "                    print(f\"Skipping row {index} again due to simulation error.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while processing row {index}: {e}\")\n",
        "                pass\n",
        "\n",
        "        print(\"\\nRetry simulation loop complete.\")\n",
        "        print(f\"Successfully generated new responses for {len(results_retry)}/{len(df_retry)} participants.\")\n",
        "\n",
        "elif 'df_retry' in locals() and df_retry.empty:\n",
        "    print(\"No skipped cases found to retry. Proceed to Block 6 to save.\")\n",
        "    results_retry = [] # Ensure list exists\n",
        "else:\n",
        "    print(\"DataFrame 'df_retry' was not created. Skipping simulation loop.\")\n",
        "    results_retry = [] # Ensure list exists"
      ],
      "metadata": {
        "id": "wmfpVrbGugwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 6 (New): Process, Combine, and Save Results\n",
        "This block replaces your old Block 6. It takes the new results, updates the df_retry DataFrame, and then sticks it back together with df_complete before saving."
      ],
      "metadata": {
        "id": "t5NOcbCG9LQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'results_retry' in locals() and results_retry:\n",
        "    # --- Process the NEW simulation results ---\n",
        "\n",
        "    # Convert the list of new results into a DataFrame\n",
        "    sim_df_retry = pd.DataFrame(results_retry)\n",
        "\n",
        "    # Use the 'index_col' to set the index for a perfect merge\n",
        "    sim_df_retry = sim_df_retry.set_index('index_col')\n",
        "\n",
        "    # --- Update the df_retry DataFrame ---\n",
        "    # This fills in the 'NA' values in our retry_df with the new simulated data\n",
        "    print(f\"Updating {len(sim_df_retry)} rows in the 'retry' dataframe...\")\n",
        "    df_retry.update(sim_df_retry)\n",
        "\n",
        "    # --- Combine and Save ---\n",
        "    # Concatenate the original good rows with the newly filled retry rows\n",
        "    final_df_re = pd.concat([df_complete, df_retry])\n",
        "\n",
        "    # Sort by the original index to restore the file's order\n",
        "    final_df_re = final_df_re.sort_index()\n",
        "\n",
        "    # If we added an 'index' column in Block 2, drop it before saving\n",
        "    if 'index' in final_df_re.columns:\n",
        "        final_df_re = final_df_re.drop(columns=['index'])\n",
        "\n",
        "    try:\n",
        "        final_df_re.to_csv(OUTPUT_PATH_RETRY, index=False)\n",
        "        print(f\"\\nSuccessfully saved combined dataset to: {OUTPUT_PATH_RETRY}\")\n",
        "        print(f\"Final data shape: {final_df_re.shape}\")\n",
        "\n",
        "        # Verify that the 'CCP2_1_1' column now has fewer (or zero) NAs\n",
        "        print(f\"Total NAs in 'CCP2_1_1' before retry: {df_full['CCP2_1_1'].isna().sum()}\")\n",
        "        print(f\"Total NAs in 'CCP2_1_1' after retry: {final_df_re['CCP2_1_1'].isna().sum()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred while saving the file: {e}\")\n",
        "\n",
        "elif 'df_complete' in locals() and 'results_retry' in locals() and not results_retry:\n",
        "    print(\"No new results were generated (or no retries were needed).\")\n",
        "    # If no retries were needed, just re-save the complete data to the new file name\n",
        "    if 'df_retry' in locals() and df_retry.empty:\n",
        "        df_complete.to_csv(OUTPUT_PATH_RETRY, index=False)\n",
        "        print(f\"Saved the original {len(df_complete)} complete cases to {OUTPUT_PATH_RETRY}.\")\n",
        "    else:\n",
        "        print(\"Retry loop ran but produced no new data. Original file not re-saved.\")\n",
        "else:\n",
        "    print(\"No results were generated. Nothing to save.\")"
      ],
      "metadata": {
        "id": "F4PiojG5uJNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One final completion"
      ],
      "metadata": {
        "id": "26putnpBHPU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration for Final Retry ---\n",
        "# We will read and overwrite the same file to finalize it.\n",
        "FILE_PATH_FINAL = \"/content/drive/MyDrive/CYON_Analysis_Materials/simulated_responses_re.csv\"\n",
        "\n",
        "print(f\"--- Starting Final Retry ---\")\n",
        "print(f\"Loading data from: {FILE_PATH_FINAL}\")\n",
        "\n",
        "# --- 1. Load Existing Data ---\n",
        "try:\n",
        "    df_full = pd.read_csv(FILE_PATH_FINAL)\n",
        "    print(f\"Successfully loaded. Total cases in file: {len(df_full)}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File not found at {FILE_PATH_FINAL}.\")\n",
        "    df_full = pd.DataFrame()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")\n",
        "    df_full = pd.DataFrame()\n",
        "\n",
        "if not df_full.empty:\n",
        "    # --- 2. Identify Skipped vs. Complete Cases ---\n",
        "\n",
        "    # Reset index to safely track rows\n",
        "    if 'index' not in df_full.columns:\n",
        "        df_full.reset_index(inplace=True)\n",
        "\n",
        "    skipped_mask = df_full['CCP2_1_1'].isna()\n",
        "    df_retry = df_full[skipped_mask].copy()\n",
        "    df_complete = df_full[~skipped_mask].copy()\n",
        "\n",
        "    initial_na_count = df_retry.shape[0]\n",
        "    print(f\"Found {len(df_complete)} already completed cases.\")\n",
        "    print(f\"Found {len(df_retry)} skipped cases to retry.\")\n",
        "\n",
        "    # --- 3. Run Simulation Loop (Only if needed) ---\n",
        "    if not df_retry.empty:\n",
        "        MODEL_NAME = \"ft:gpt-4o-2024-08-06:personal::A8vV3mNd\"\n",
        "        results_retry = []\n",
        "        client = None\n",
        "\n",
        "        try:\n",
        "            if \"OPENAI_API_KEY\" not in os.environ:\n",
        "                raise EnvironmentError(\"OPENAI_API_KEY environment variable not set. Please re-run Block 1.\")\n",
        "            client = OpenAI()\n",
        "            print(f\"OpenAI client initialized. Using model: {MODEL_NAME}\")\n",
        "        except Exception as e:\n",
        "            print(f\"FATAL ERROR: Could not initialize OpenAI client: {e}\")\n",
        "\n",
        "        if client:\n",
        "            print(f\"Starting simulation retry for {len(df_retry)} participants...\")\n",
        "            for index, row in tqdm(df_retry.iterrows(), total=len(df_retry), desc=\"Retrying Final Cases\"):\n",
        "                try:\n",
        "                    sim_data = simulate_single_participant(\n",
        "                        row, client, MODEL_NAME,\n",
        "                        pre_survey_human_vars, pre_survey_q_map,\n",
        "                        post_survey_q_map, treatment_var\n",
        "                    )\n",
        "                    if sim_data:\n",
        "                        sim_data['index'] = index # Use the 'index' column for merging\n",
        "                        results_retry.append(sim_data)\n",
        "                    else:\n",
        "                        print(f\"Skipping row {index} again due to simulation error.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"An error occurred while processing row {index}: {e}\")\n",
        "\n",
        "            print(f\"\\nRetry loop complete. Successfully generated new responses for {len(results_retry)}/{len(df_retry)} cases.\")\n",
        "\n",
        "            # --- 4. Process New Results ---\n",
        "            if results_retry:\n",
        "                sim_df_retry = pd.DataFrame(results_retry)\n",
        "                sim_df_retry = sim_df_retry.set_index('index')\n",
        "\n",
        "                # Use update() to fill in the missing values in our retry dataframe\n",
        "                print(f\"Updating {len(sim_df_retry)} rows in the 'retry' dataframe...\")\n",
        "                df_retry.set_index('index', inplace=True) # Align indices for update\n",
        "                df_retry.update(sim_df_retry)\n",
        "\n",
        "                # Re-align df_complete index for final concat\n",
        "                df_complete.set_index('index', inplace=True)\n",
        "\n",
        "    # --- 5. Combine and Save Final Data ---\n",
        "    try:\n",
        "        # Combine the original good rows with the newly filled retry rows\n",
        "        final_df_re = pd.concat([df_complete, df_retry])\n",
        "\n",
        "        # Sort by the original index to restore the file's order\n",
        "        final_df_re = final_df_re.sort_index()\n",
        "\n",
        "        # Drop the 'index' column we added, if it exists\n",
        "        if 'index' in final_df_re.columns:\n",
        "            final_df_re = final_df_re.drop(columns=['index'])\n",
        "        # Also drop the 'index_col' from the very first run, if it's there\n",
        "        if 'index_col' in final_df_re.columns:\n",
        "            final_df_re = final_df_re.drop(columns=['index_col'])\n",
        "\n",
        "        final_df_re.to_csv(FILE_PATH_FINAL, index=False)\n",
        "\n",
        "        print(f\"\\n--- Operation Complete ---\")\n",
        "        print(f\"Successfully saved fully completed dataset to: {FILE_PATH_FINAL}\")\n",
        "        print(f\"Final data shape: {final_df_re.shape}\")\n",
        "\n",
        "        final_na_count = final_df_re['CCP2_1_1'].isna().sum()\n",
        "        print(f\"Total NAs in 'CCP2_1_1' before retry: {initial_na_count}\")\n",
        "        print(f\"Total NAs in 'CCP2_1_1' after retry:  {final_na_count}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred while saving the file: {e}\")\n",
        "\n",
        "elif df_full.empty:\n",
        "    print(\"Could not proceed because the input file was not loaded.\")\n",
        "else:\n",
        "    print(\"No cases to retry. File is already complete.\")"
      ],
      "metadata": {
        "id": "Lr94MfESHZZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}