{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxw0CBPL6z5tk24E3qPcMi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casllmproject/bending_effect/blob/main/C1_1_DQPD_GPT_CA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SCTnUSYx2q11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Chunk 1: Setup, Configuration, and Data Loading\n",
        "This chunk handles all the initial setup, including installing libraries, mounting Google Drive, and loading target data."
      ],
      "metadata": {
        "id": "MEXWETZsOiK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from google.colab import drive\n",
        "import time\n",
        "\n",
        "# =========================================================================\n",
        "# 0. CONFIGURATION & SETUP\n",
        "# =========================================================================\n",
        "# --- CONFIGURATION ---\n",
        "TARGET_MODEL = \"gpt-4-turbo\"\n",
        "MAX_RETRIES = 5              # Max attempts to code a single text on failure\n",
        "INSPECTION_SIZE = 10         # Number of cases for the initial inspection batch\n",
        "CODING_COLUMNS = [\"RAT\", \"BGI\", \"ETV\", \"REC\", \"DIS\", \"ACK\", \"OPN\", \"SOL\"]\n",
        "FILE_PATH = \"/content/drive/MyDrive/CYON_Analysis_Materials/Main_Test/Final_Cleaned_Dec18.csv\"\n",
        "OUTPUT_FILE_PATH = FILE_PATH.replace(\".csv\", \"_FULL_CODED_USER.csv\")\n",
        "\n",
        "# --- SETUP ---\n",
        "print(\"--- STARTING LLM CONTENT ANALYSIS SCRIPT ---\")\n",
        "\n",
        "# Set API Key\n",
        "try:\n",
        "    client = OpenAI(api_key=\" \")\n",
        "    print(\"‚úÖ OpenAI client initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERROR: Failed to initialize OpenAI client. Check API key. {e}\")\n",
        "    # Consider raising an error here to stop execution if the key is bad\n",
        "\n",
        "# Load the Data\n",
        "try:\n",
        "    df2 = pd.read_csv(FILE_PATH)\n",
        "    print(f\"‚úÖ DataFrame 'df2' loaded successfully with {len(df2)} rows.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå FATAL ERROR: Could not load file from {FILE_PATH}. Script stopping. {e}\")\n",
        "    raise\n",
        "\n",
        "df2_original = df2.copy()\n",
        "original_cols = df2_original.columns.tolist()"
      ],
      "metadata": {
        "id": "osalv1oSLs9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Chunk 2: Coding Instructions and Robust Function\n",
        "This chunk defines the comprehensive system prompt and the robust function that handles the API call, JSON parsing, and retry logic."
      ],
      "metadata": {
        "id": "8FFnngSDOjgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# 1. CODING INSTRUCTIONS (SYSTEM PROMPT) - FULL DETAIL\n",
        "# =========================================================================\n",
        "\n",
        "CODING_INSTRUCTIONS = \"\"\"\n",
        "You are a highly-skilled social scientific research assistant specializing in content analysis.\n",
        "Your task is to analyze a mobile message that shares a news article about U.S. climate policy and code it according to the following eight categories.\n",
        "Your output MUST be a valid JSON object with the exact keys provided below.\n",
        "Do not include any explanation, introductory text, or other characters outside of the JSON.\n",
        "\n",
        "---\n",
        "CODING SCHEME:\n",
        "---\n",
        "1. Rationality (RAT):\n",
        "  - Reasoning: Does the sender explicitly try to justify the reason why they are sending this message?\n",
        "  - Instruction: Code YES when the text explicitly elaborates why the sender wants the receiver to see this news. The use of words such as \"because\", \"due to\", \"therefore\", ‚Äúreasons‚Äù, ‚Äúwhy‚Äù can signal an attempt at justification, but texts without these words may still be coded as YES if the comment follows a clear line of reasoning.\n",
        "  - Example: \"it would be really cool for you to read this article to understand why I believe in policies\", \"we all need to do our part and climbing change because it affects us all and we all have to live on this planet.\"\n",
        "  - Coding Scheme: No = 0, Yes = 1, Very YES (If such expressions appear more than once) = 2\n",
        "\n",
        "2. Background Information (BGI):\n",
        "  - Reasoning: Does the sender describe the contextual background for why they are sending the message?\n",
        "  - Instruction: Code YES when the text describes the broader context or societal issues embedded in the topic.\n",
        "  - Example: \"Trump wants to withdraw from the Paris agreement\", \"In regard to the current financial conditions of the US...\"\n",
        "  - Coding Scheme: No = 0, Yes = 1, Very YES (If such expressions appear more than once) = 2\n",
        "\n",
        "3. External Evidence (ETV):\n",
        "  - Reasoning: Does the sender provide external evidence in their message?\n",
        "  - Instruction: Code YES when the text elaborates on the opinion using facts, media sources, politicians‚Äô statements, or other verifiable evidence. Code YES when the text refers to authorities or experts to support the messege.\n",
        "  - Example: \"Recent studies show green energy is a rapidly growing economic sector\", ‚ÄúTrump said...‚Äù, \"Scientists show...\" ‚ÄúAccording to the New York Times...‚Äù\n",
        "  - Coding Scheme: No = 0, Yes = 1, Very YES (If such expressions appear more than once) = 2\n",
        "\n",
        "4. Reciprocity (REC):\n",
        "  - Reasoning: Does the sender express curiosity about the receiver‚Äôs thoughts or ask a question?\n",
        "  - Instruction: Code YES when the text uses a question or expressions such as ‚Äúcurious‚Äù, ‚Äúwonder‚Äù, ‚Äúwant to know‚Äù, \"let's talk\".\n",
        "  - Example: \"I'm curious to hear what you think about it.\", \"Please see this and let me know how you think\", \"Tell me...\"\n",
        "  - Coding Scheme: No = 0, Yes = 1, Very YES (If such expressions appear more than once) = 2\n",
        "\n",
        "5. Disrespect (DIS):\n",
        "  - Reasoning: Does the sender show uncivil attitudes toward the receiver or toward the position of a particular group?\n",
        "  - Instruction: Code as YES when the text contains expressions implying that the opposing position on the issue is irrational, inferior, ridiculous, or should be excluded from discussion.\n",
        "  - Example: \"This is stupid\", \"idiot\", ‚ÄúTrump‚Äôs withdrawal from the Paris Agreement will definitely hurt our country‚Äù, \"They are liar\", \"Liberals are hypocratic\", \"They should stop...\"\n",
        "  - Coding Scheme: No = 0, Yes = -1, Very YES (If such expressions appear more than once) = -2\n",
        "\n",
        "6. Acknowledgement (ACK):\n",
        "  - Reasoning: Does the sender express how they view the receiver‚Äôs opinion of them or vice versa?\n",
        "  - Instruction: Code YES when the text describes differences in opinion between the sender and the receiver.\n",
        "  - Example: ‚Äúyour belief might be different than mine‚Äù, ‚ÄúI believe we have different views on climate change‚Äù, \"although we disagree each other..\"\n",
        "  - Coding Scheme: No = 0, Yes = 1, Very YES (If such expressions appear more than once) = 2\n",
        "\n",
        "7. Openness (OPN):\n",
        "  - Reasoning: Does the sender suggest that different perspectives can be viewed fairly?\n",
        "  - Instruction: Code YES when the text explicitly states that perspectives on the issue can be presented fairly, using expressions such as ‚Äúfair‚Äù, ‚Äúbalanced‚Äù, ‚Äúboth sides‚Äù.\n",
        "  - Example: ‚ÄúThis is a pretty fair assessment of the situation that shows both sides of the debate‚Äù, ‚Äúwe can all get a more balanced perspective‚Äù\n",
        "  - Coding Scheme: No = 0, Yes = 1, Very YES (If such expressions appear more than once) = 2\n",
        "\n",
        "8. Solution (SOL):\n",
        "  - Reasoning: Does the sender propose a joint solution to the receiver?\n",
        "  - Instruction: Code YES when the text suggests common solutions or alternatives that people with differing positions on the issue may commonly accept.\n",
        "  - Example: ‚ÄúThere are alternative solutions that can lead to a more sustainable future‚Äù, \"This solution...\", \"We need to work together\", ‚Äúthe article can help us find some common grounds‚Äù\n",
        "  - Coding Scheme: No = 0, Yes = 1, Very YES (If such expressions appear more than once) = 2\n",
        "---\n",
        "OUTPUT FORMAT:\n",
        "Your final output MUST be a JSON object with the following keys:\n",
        "{\n",
        "  \"RAT\": <int>, \"BGI\": <int>, \"ETV\": <int>, \"REC\": <int>,\n",
        "  \"DIS\": <int>, \"ACK\": <int>, \"OPN\": <int>, \"SOL\": <int>\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# =========================================================================\n",
        "# 2. ROBUST CODING FUNCTION (Handles retry logic and errors)\n",
        "# =========================================================================\n",
        "\n",
        "def code_text_with_llm(text_to_code: str, model_name: str, max_retries: int):\n",
        "    \"\"\"Calls LLM API with retry logic and error handling (JSON, API failure).\"\"\"\n",
        "    # Skip if text is missing or empty\n",
        "    if pd.isna(text_to_code) or str(text_to_code).strip() == \"\":\n",
        "        return None\n",
        "\n",
        "    attempt = 0\n",
        "    while attempt < max_retries:\n",
        "        try:\n",
        "            completion = client.chat.completions.create(\n",
        "                model=model_name,\n",
        "                response_format={\"type\": \"json_object\"},\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": CODING_INSTRUCTIONS},\n",
        "                    {\"role\": \"user\", \"content\": f\"Code the following news text: '{text_to_code}'\"}\n",
        "                ],\n",
        "                temperature=0.0\n",
        "            )\n",
        "\n",
        "            raw_output = completion.choices[0].message.content\n",
        "            coded_data = json.loads(raw_output)\n",
        "\n",
        "            # Basic validation: ensure all 8 keys are present\n",
        "            expected_keys = set(CODING_COLUMNS)\n",
        "            if expected_keys.issubset(set(coded_data.keys())):\n",
        "                return coded_data\n",
        "            else:\n",
        "                print(f\"\\n  --> Retry {attempt+1}/{max_retries}: JSON validation failed (missing keys).\")\n",
        "                attempt += 1\n",
        "                time.sleep(2)\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"\\n  --> Retry {attempt+1}/{max_retries}: Failed to decode JSON response.\")\n",
        "            attempt += 1\n",
        "            time.sleep(2)\n",
        "        except Exception as e:\n",
        "            print(f\"\\n  --> Retry {attempt+1}/{max_retries}: API Error ({type(e).__name__}). Waiting 5 seconds...\")\n",
        "            attempt += 1\n",
        "            time.sleep(5)\n",
        "\n",
        "    print(f\"*** Failed to code text after {max_retries} attempts.\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "Mb8IiwIJL8yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Chunk 3: Phase 1 - Inspection Batch (First 10 Cases)\n",
        "This chunk runs the first 10 cases and prints the results for the manual inspection."
      ],
      "metadata": {
        "id": "eBoxdo_ZOorA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# 3. PHASE 1: INSPECTION BATCH (First 10 Cases)\n",
        "# =========================================================================\n",
        "\n",
        "print(\"\\n\\n--- PHASE 1: INSPECTION BATCH (First 10 Cases) ---\")\n",
        "\n",
        "# 1. Split data\n",
        "df2_inspection = df2.head(INSPECTION_SIZE).copy()\n",
        "df2_remainder = df2.iloc[INSPECTION_SIZE:].copy()\n",
        "print(f\"Inspection Batch size: {len(df2_inspection)} | Remainder Batch size: {len(df2_remainder)}\")\n",
        "\n",
        "# Initialize columns with pd.NA for missing values\n",
        "for col in CODING_COLUMNS:\n",
        "    df2_inspection[col] = pd.NA\n",
        "\n",
        "coded_count = 0\n",
        "skipped_count = 0\n",
        "total_rows = len(df2_inspection)\n",
        "\n",
        "for i, row in df2_inspection.iterrows():\n",
        "    text_to_code = row['OE1']\n",
        "\n",
        "    # Show progress\n",
        "    progress_percent = ((i - df2_inspection.index.min() + 1) / total_rows) * 100\n",
        "    print(f\"Processing case {i + 1}/{total_rows} ({progress_percent:.0f}%)...\", end=\"\\r\")\n",
        "\n",
        "    if pd.isna(text_to_code) or str(text_to_code).strip() == \"\":\n",
        "        skipped_count += 1\n",
        "        continue\n",
        "\n",
        "    coded_values = code_text_with_llm(text_to_code, TARGET_MODEL, MAX_RETRIES)\n",
        "\n",
        "    if coded_values:\n",
        "        for key in CODING_COLUMNS:\n",
        "            # Assign coded value or pd.NA if key is missing from LLM output\n",
        "            df2_inspection.loc[i, key] = coded_values.get(key, pd.NA)\n",
        "        coded_count += 1\n",
        "    else:\n",
        "        # If LLM failed to code, assign pd.NA to all coding columns for this row\n",
        "        for key in CODING_COLUMNS:\n",
        "            df2_inspection.loc[i, key] = pd.NA\n",
        "        skipped_count += 1\n",
        "\n",
        "# Convert coding columns to nullable integer type (Int64Dtype)\n",
        "for col in CODING_COLUMNS:\n",
        "    df2_inspection[col] = df2_inspection[col].astype(pd.Int64Dtype())\n",
        "\n",
        "print(f\"\\n\\n‚úÖ PHASE 1 COMPLETE. Total Coded: {coded_count}, Skipped/Failed: {total_rows - coded_count}.\")\n",
        "print(\"\\n*** INSPECTION BATCH RESULTS (df2_inspection) ***\")\n",
        "print(df2_inspection[['OE1'] + CODING_COLUMNS])\n",
        "\n",
        "print(\"\\n\\n#################################################################\")\n",
        "print(\"üõë PAUSE: Review the 10 cases above. Run the next cell ONLY if satisfied.\")\n",
        "print(\"#################################################################\")"
      ],
      "metadata": {
        "id": "PPRRggV6MEgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Chunk 4: Phase 2 - Remainder Batch\n",
        "Run this chunk after reviewed and approved the results from Chunk 3. It codes the rest of the dataset."
      ],
      "metadata": {
        "id": "qXNZRc-sOqVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# 4. PHASE 2: REMAINDER BATCH\n",
        "# =========================================================================\n",
        "\n",
        "# Initialize columns for the remainder DataFrame with pd.NA\n",
        "for col in CODING_COLUMNS:\n",
        "    df2_remainder[col] = pd.NA\n",
        "\n",
        "coded_count = 0\n",
        "skipped_count = 0\n",
        "total_rows = len(df2_remainder)\n",
        "\n",
        "print(f\"\\n\\n--- PHASE 2: Coding Remainder Batch ({total_rows} cases) ---\")\n",
        "\n",
        "# Iterate over the Remainder Batch and apply the coding function\n",
        "for i, row in df2_remainder.iterrows():\n",
        "    text_to_code = row['OE1']\n",
        "\n",
        "    # Show progress every 5 cases\n",
        "    current_case_num = i - df2_remainder.index.min() + 1\n",
        "    progress_percent = (current_case_num / total_rows) * 100\n",
        "    if current_case_num % 5 == 0 or current_case_num == total_rows:\n",
        "        print(f\"Progress: {current_case_num}/{total_rows} rows processed ({progress_percent:.2f}%). Coded: {coded_count}, Skipped: {skipped_count}.\")\n",
        "\n",
        "    if pd.isna(text_to_code) or str(text_to_code).strip() == \"\":\n",
        "        skipped_count += 1\n",
        "        continue\n",
        "\n",
        "    coded_values = code_text_with_llm(text_to_code, TARGET_MODEL, MAX_RETRIES)\n",
        "\n",
        "    if coded_values:\n",
        "        for key in CODING_COLUMNS:\n",
        "            # Assign coded value or pd.NA if key is missing from LLM output\n",
        "            df2_remainder.loc[i, key] = coded_values.get(key, pd.NA)\n",
        "        coded_count += 1\n",
        "    else:\n",
        "        # If LLM failed to code, assign pd.NA to all coding columns for this row\n",
        "        for key in CODING_COLUMNS:\n",
        "            df2_remainder.loc[i, key] = pd.NA\n",
        "        skipped_count += 1\n",
        "\n",
        "print(\"\\n‚úÖ PHASE 2 CODING COMPLETE.\")\n",
        "print(f\"Final Counts: Successfully Coded = {coded_count}, Skipped/Failed = {total_rows - coded_count}.\")\n",
        "\n",
        "# Convert the new coding columns to nullable integers\n",
        "for col in CODING_COLUMNS:\n",
        "    df2_remainder[col] = df2_remainder[col].astype(pd.Int64Dtype())"
      ],
      "metadata": {
        "id": "RrHSBGuINYbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Chunk 5: Concatenate and Save Results\n",
        "This final chunk combines the two batches and saves the complete, coded DataFrame to Google Drive."
      ],
      "metadata": {
        "id": "VikeWiYZOvHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# 4.CALCULATE COMPOSITE SCORE (COMP) - Based on Created Columns\n",
        "# =========================================================================\n",
        "\n",
        "# Define the columns that were successfully created by the LLM function\n",
        "# (excluding DISC due to its negative scoring convention).\n",
        "SUM_COLUMNS = [\"RAT\", \"BGI\", \"ETV\", \"REC\", \"DIS\", \"ACK\", \"OPN\", \"SOL\"]\n",
        "COMP_COLUMN_NAME = \"DQPD\"\n",
        "\n",
        "print(\"\\n--- CALCULATING COMPOSITE SCORE ---\")\n",
        "\n",
        "# --- 1. Inspection Batch (df2_inspection) ---\n",
        "try:\n",
        "    # Calculate the row-wise sum for the specified columns\n",
        "    df2_inspection[COMP_COLUMN_NAME] = df2_inspection[SUM_COLUMNS].sum(axis=1)\n",
        "    print(f\"‚úÖ COMP score added to df2_inspection (Sum of {', '.join(SUM_COLUMNS)}).\")\n",
        "except KeyError as e:\n",
        "    # This should not happen if the coding phases ran correctly\n",
        "    print(f\"‚ùå ERROR in df2_inspection: Column {e} not found. Check your coding phase results.\")\n",
        "    df2_inspection[COMP_COLUMN_NAME] = pd.NA\n",
        "\n",
        "# --- 2. Remainder Batch (df2_remainder) ---\n",
        "try:\n",
        "    # Calculate the row-wise sum for the specified columns\n",
        "    df2_remainder[COMP_COLUMN_NAME] = df2_remainder[SUM_COLUMNS].sum(axis=1)\n",
        "    print(f\"‚úÖ COMP score added to df2_remainder (Sum of {', '.join(SUM_COLUMNS)}).\")\n",
        "except KeyError as e:\n",
        "    print(f\"‚ùå ERROR in df2_remainder: Column {e} not found. Check your coding phase results.\")\n",
        "    df2_remainder[COMP_COLUMN_NAME] = pd.NA\n",
        "\n",
        "print(f\"\\nExample COMP values from Inspection Batch (first 5 rows):\\n{df2_inspection[COMP_COLUMN_NAME].head()}\")\n",
        "print(\"You can now proceed with Chunk 5: CONCATENATE AND SAVE.\")"
      ],
      "metadata": {
        "id": "5A29XSlp8iCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# 5. CONCATENATE AND SAVE\n",
        "# =========================================================================\n",
        "\n",
        "# Combine the Inspection Batch and the Remainder Batch\n",
        "df2_final_coded = pd.concat([df2_inspection, df2_remainder])\n",
        "\n",
        "# Ensure the final DataFrame is sorted by the original index\n",
        "df2_final_coded = df2_final_coded.sort_index()\n",
        "\n",
        "try:\n",
        "    df2_final_coded.to_csv(OUTPUT_FILE_PATH, index=False)\n",
        "    print(f\"\\n\\n‚úÖ FULL CODED DataFrame successfully saved to: {OUTPUT_FILE_PATH}\")\n",
        "    print(f\"Total rows in saved file: {len(df2_final_coded)}\")\n",
        "    print(\"The new file includes your original data plus the RAT, BGI, ETV, DIV, DIS, NRE, INT, MET, DQPD columns.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERROR: Failed to save the final file. Check your Google Drive permissions. Error: {e}\")"
      ],
      "metadata": {
        "id": "8S6DMUsENoWB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}