{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU/TsfBhj0wK6fIRbJFT53",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casllmproject/bending_effect/blob/main/C2_1_SBERT_simul_text_similarity_Main_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lpGZjoF12K8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block1: Setup Data"
      ],
      "metadata": {
        "id": "ium2mCal4aQa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvHa68RXsW0H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import mannwhitneyu\n",
        "from itertools import combinations\n",
        "import warnings\n",
        "\n",
        "# Define the file path\n",
        "file_path = \"/content/drive/MyDrive/CYON_Analysis_Materials/Main_Test/Final_Cleaned_Dec18.csv\"\n",
        "\n",
        "# Read the CSV file into DataFrame df1\n",
        "try:\n",
        "    df1 = pd.read_csv(file_path)\n",
        "    print(\"File loaded successfully.\")\n",
        "    print(\"First 5 rows of your data:\")\n",
        "    print(df1.head())\n",
        "    print(\"\\nDataFrame Info:\")\n",
        "    df1.info()\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Remove fixed introductory sentences from generatedBody\n",
        "    # ------------------------------------------------------------------\n",
        "    prefix = (\n",
        "        \"The Trump administration announced the U.S. withdrawal from the Paris Agreement in January 2025. \"\n",
        "        \"This decision comes with far-reaching implications.\"\n",
        "    )\n",
        "\n",
        "    df1[\"ed_generatedBody\"] = (\n",
        "        df1[\"generatedBody\"]\n",
        "        .str.replace(prefix, \"\", regex=False)\n",
        "        .str.lstrip()\n",
        "    )\n",
        "\n",
        "    print(\"\\nText cleaning completed. 'ed_generatedBody' column created.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "    print(\"Please check the file path and try again.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 2: Generate Embeddings and Similarity MatrixThis is the most computationally expensive step. We encode all texts into SBERT vectors and then compute a single, large $N \\times N$ similarity matrix, where $N$ is the total number of texts. We will reuse this matrix for all subsequent analyses."
      ],
      "metadata": {
        "id": "-F-ivIiw4d49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained SBERT model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "print(\"Encoding texts... This may take a while.\")\n",
        "\n",
        "# --- IMPORTANT ---\n",
        "# Make sure 'ed_generatedBody' is the correct column name from Block 1's output!\n",
        "try:\n",
        "    texts = df1['ed_generatedBody'].tolist()\n",
        "except KeyError:\n",
        "    print(\"=\"*50)\n",
        "    print(\"ERROR: Could not find column 'ed_generatedBody'.\")\n",
        "    print(\"Please check the column names printed in Block 1 and\")\n",
        "    print(\"update the 'texts = df1['...']' line in Block 2 with your correct text column.\")\n",
        "    print(\"=\"*50)\n",
        "    # Stop execution by raising the error again\n",
        "    raise\n",
        "\n",
        "embeddings = model.encode(texts, show_progress_bar=True)\n",
        "print(\"Embeddings generated. Shape:\", embeddings.shape)\n",
        "\n",
        "# Calculate the pairwise cosine similarity matrix for all texts\n",
        "print(\"Calculating full similarity matrix...\")\n",
        "similarity_matrix = cosine_similarity(embeddings)\n",
        "print(\"Similarity matrix shape:\", similarity_matrix.shape)"
      ],
      "metadata": {
        "id": "azWISBQJzppR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 3: Define Reusable Analysis Function\n",
        "This block defines the master function. You only need to run this block once to \"teach\" Python the function."
      ],
      "metadata": {
        "id": "s3z633zz4u8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_similarity_analysis(df, group_column_name, similarity_matrix):\n",
        "    \"\"\"\n",
        "    Performs a 3-part similarity analysis on a dataframe\n",
        "    for a specified grouping column.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataframe containing the group labels.\n",
        "        group_column_name (str): The name of the column to group by.\n",
        "        similarity_matrix (np.array): The pre-computed N x N similarity matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"#\"*60)\n",
        "    print(f\"  RUNNING ANALYSIS FOR: '{group_column_name}'\")\n",
        "    print(\"#\"*60)\n",
        "\n",
        "    # Ensure the column exists\n",
        "    if group_column_name not in df.columns:\n",
        "        print(f\"ERROR: Column '{group_column_name}' not found in DataFrame.\")\n",
        "        print(\"Skipping this analysis.\")\n",
        "        return\n",
        "\n",
        "    # Make sure group values are non-null\n",
        "    df_analysis = df[[group_column_name]].copy()\n",
        "    df_analysis = df_analysis.dropna(subset=[group_column_name])\n",
        "\n",
        "    groups = sorted(df_analysis[group_column_name].unique())\n",
        "    print(f\"Found {len(groups)} unique groups: {groups}\")\n",
        "\n",
        "    all_within_scores = {}\n",
        "    within_group_results = {}\n",
        "\n",
        "    # --- Part 1: Within-Group Similarity ---\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(\"Part 1: Within-Group Similarity\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    for group in groups:\n",
        "        group_indices = df_analysis[df_analysis[group_column_name] == group].index.tolist()\n",
        "\n",
        "        if len(group_indices) < 2:\n",
        "            print(f\"Group '{group}' has fewer than 2 items, skipping.\")\n",
        "            continue\n",
        "\n",
        "        sub_matrix = similarity_matrix[np.ix_(group_indices, group_indices)]\n",
        "        iu_indices = np.triu_indices_from(sub_matrix, k=1)\n",
        "        within_scores = sub_matrix[iu_indices]\n",
        "\n",
        "        if len(within_scores) > 0:\n",
        "            all_within_scores[group] = within_scores\n",
        "            mean_similarity = np.mean(within_scores)\n",
        "            within_group_results[group] = mean_similarity\n",
        "            print(f\"  - Group '{group}' (N={len(group_indices)}): Avg Similarity = {mean_similarity:.4f}\")\n",
        "        else:\n",
        "            print(f\"  - Group '{group}' (N={len(group_indices)}): Not enough pairs for comparison.\")\n",
        "\n",
        "    # --- Part 2: Between-Group Similarity ---\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(\"Part 2: Between-Group Similarity (Difference)\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    between_group_results = {}\n",
        "    for group1, group2 in combinations(groups, 2):\n",
        "        group1_indices = df_analysis[df_analysis[group_column_name] == group1].index.tolist()\n",
        "        group2_indices = df_analysis[df_analysis[group_column_name] == group2].index.tolist()\n",
        "\n",
        "        if not group1_indices or not group2_indices:\n",
        "            continue\n",
        "\n",
        "        sub_matrix = similarity_matrix[np.ix_(group1_indices, group2_indices)]\n",
        "        between_scores = sub_matrix.flatten()\n",
        "\n",
        "        if len(between_scores) > 0:\n",
        "            mean_similarity = np.mean(between_scores)\n",
        "            pair_name = f\"{group1} <-> {group2}\"\n",
        "            between_group_results[pair_name] = mean_similarity\n",
        "            print(f\"  - Pair '{pair_name}': Avg Similarity = {mean_similarity:.4f}\")\n",
        "\n",
        "    # --- Part 3: Statistical Significance ---\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(\"Part 3: Statistical Significance\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    stat_results = []\n",
        "\n",
        "    # Suppress warnings from Mann-Whitney U test (e.g., ties)\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "\n",
        "        for group in groups:\n",
        "            within_scores = all_within_scores.get(group)\n",
        "\n",
        "            if within_scores is None or len(within_scores) == 0:\n",
        "                print(f\"  - Group '{group}': Skipping (no within-group pairs).\")\n",
        "                continue\n",
        "\n",
        "            group_indices = df_analysis[df_analysis[group_column_name] == group].index.tolist()\n",
        "            other_indices = df_analysis[df_analysis[group_column_name] != group].index.tolist()\n",
        "\n",
        "            if not other_indices:\n",
        "                print(f\"  - Group '{group}': Skipping (no other groups to compare to).\")\n",
        "                continue\n",
        "\n",
        "            sub_matrix = similarity_matrix[np.ix_(group_indices, other_indices)]\n",
        "            between_scores = sub_matrix.flatten()\n",
        "\n",
        "            if len(between_scores) == 0:\n",
        "                print(f\"  - Group '{group}': Skipping (no between-group pairs).\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                stat, p_value = mannwhitneyu(\n",
        "                    within_scores,\n",
        "                    between_scores,\n",
        "                    alternative='greater'\n",
        "                )\n",
        "\n",
        "                mean_within = np.mean(within_scores)\n",
        "                mean_between = np.mean(between_scores)\n",
        "\n",
        "                stat_results.append({\n",
        "                    'Group': group,\n",
        "                    'Mean_Within_Sim': mean_within,\n",
        "                    'Mean_Between_Sim': mean_between,\n",
        "                    'U_Statistic': stat,\n",
        "                    'p_value': p_value,\n",
        "                    'Significant (p<0.05)': p_value < 0.05\n",
        "                })\n",
        "\n",
        "            except ValueError:\n",
        "                 print(f\"  - Group '{group}': Could not run test (e.g., zero variance).\")\n",
        "\n",
        "    if stat_results:\n",
        "        df_stats = pd.DataFrame(stat_results)\n",
        "        df_stats = df_stats.set_index('Group')\n",
        "        print(\"\\n--- Summary of Statistical Significance ---\")\n",
        "        print(df_stats.to_string(float_format=\"%.6f\"))\n",
        "    else:\n",
        "        print(\"\\nNo statistical results to display.\")\n",
        "\n",
        "    print(\"\\n\" + \"#\"*60)\n",
        "    print(f\"  ANALYSIS FOR '{group_column_name}' COMPLETE\")\n",
        "    print(\"#\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Reusable analysis function 'perform_similarity_analysis' is defined.\")"
      ],
      "metadata": {
        "id": "1vgK5HDgzMNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block 4: Analysis - Run for \"DISP\"\n",
        "This block calls the same function on \"Group\" column.\n"
      ],
      "metadata": {
        "id": "ONo-HOjd4920"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the complete analysis for the 'Group' column\n",
        "perform_similarity_analysis(\n",
        "    df=df1,\n",
        "    group_column_name='DISP',\n",
        "    similarity_matrix=similarity_matrix\n",
        ")"
      ],
      "metadata": {
        "id": "32BPDo4mzXbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import *\n",
        "\n",
        "# 1. Prepare the data from your summary table\n",
        "data = {\n",
        "    'Group': ['DISP 0', 'DISP 1', 'DISP 2', 'DISP 3'],\n",
        "    'Mean_Within_Sim': [0.783628, 0.850774, 0.827533, 0.825771],\n",
        "    'Mean_Between_Sim': [0.753403, 0.777711, 0.766096, 0.703685],\n",
        "    'p_value': [0.000000, 0.000000, 0.000000, 0.000000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 2. Reshape data to 'long format'\n",
        "df_melted = df.melt(\n",
        "    id_vars=['Group', 'p_value'],\n",
        "    value_vars=['Mean_Within_Sim', 'Mean_Between_Sim'],\n",
        "    var_name='Metric',\n",
        "    value_name='Similarity'\n",
        ")\n",
        "\n",
        "df_melted['Metric'] = df_melted['Metric'].replace({\n",
        "    'Mean_Within_Sim': 'Within-Group',\n",
        "    'Mean_Between_Sim': 'Between-Group'\n",
        "})\n",
        "\n",
        "# 3. Helper for significance annotations\n",
        "df_stars = df.copy()\n",
        "df_stars['label'] = '***'\n",
        "# Place stars slightly above the highest bar in each group\n",
        "df_stars['y_pos'] = df[['Mean_Within_Sim', 'Mean_Between_Sim']].max(axis=1) + 0.05\n",
        "\n",
        "# 4. Construct and display the plot\n",
        "# Wrapping the plot in parentheses and ensuring it's the last line triggers Colab's auto-render\n",
        "plot = (\n",
        "    ggplot(df_melted, aes(x='Group', y='Similarity', fill='Metric'))\n",
        "    + geom_col(position='dodge', width=0.7, color=\"#333333\", size=0.2)\n",
        "    + geom_text(\n",
        "        data=df_stars,\n",
        "        mapping=aes(x='Group', y='y_pos', label='label'),\n",
        "        inherit_aes=False,\n",
        "        size=18,\n",
        "        va='bottom'\n",
        "    )\n",
        "    + scale_fill_manual(values=[\"#BDC3C7\", \"#2C3E50\"]) # Professional Grayscale/Navy\n",
        "    + labs(\n",
        "        title='Comparative Analysis of Group Similarity Metrics',\n",
        "        subtitle='Significance: *** p < 0.001 (Mann-Whitney U Test)',\n",
        "        x='Experimental Groups',\n",
        "        y='Mean Cosine Similarity',\n",
        "        fill='Similarity Type'\n",
        "    )\n",
        "    + scale_y_continuous(expand=(0, 0, 0.1, 0), limits=(0, 1.0))\n",
        "    + theme_classic()\n",
        "    + theme(\n",
        "        figure_size=(10, 6),\n",
        "        title=element_text(size=14, weight='bold'),\n",
        "        legend_position='right',\n",
        "        axis_line=element_line(size=1, color=\"black\"),\n",
        "        panel_grid_major_y=element_line(color=\"lightgrey\", linetype=\"dashed\")\n",
        "    )\n",
        ")\n",
        "\n",
        "# This line ensures the plot is shown in Colab\n",
        "plot.draw()"
      ],
      "metadata": {
        "id": "0dF2Tt8tXMw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NMd8cLd6Yvjy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}